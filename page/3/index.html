<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.1.1">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css" integrity="sha256-yIDrPSXHZdOZhAqiBP7CKzIwMQmRCJ8UeB8Jo17YC4o=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"guoltan.github.io","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.19.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta property="og:type" content="website">
<meta property="og:title" content="guoltan个人博客">
<meta property="og:url" content="https://guoltan.github.io/page/3/index.html">
<meta property="og:site_name" content="guoltan个人博客">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="guoltan">
<meta property="article:tag" content="摸鱼，自嗨，困奋">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://guoltan.github.io/page/3/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"page/3/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>guoltan个人博客</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<link rel="alternate" href="/atom.xml" title="guoltan个人博客" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">guoltan个人博客</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">guoltan</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">24</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">11</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/guoltan" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;guoltan" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:897156356@qq.com" title="E-Mail → mailto:897156356@qq.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://guoltan.github.io/2021/09/08/Docker0%E5%AD%90%E7%BD%91%E5%86%B2%E7%AA%81%E5%AF%BC%E8%87%B4%E8%8A%82%E7%82%B9%E6%89%A9%E5%AE%B9%E5%A4%B1%E8%B4%A5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="guoltan">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="guoltan个人博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | guoltan个人博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/09/08/Docker0%E5%AD%90%E7%BD%91%E5%86%B2%E7%AA%81%E5%AF%BC%E8%87%B4%E8%8A%82%E7%82%B9%E6%89%A9%E5%AE%B9%E5%A4%B1%E8%B4%A5/" class="post-title-link" itemprop="url">Docker0子网冲突导致节点扩容失败</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-09-08 18:00:15" itemprop="dateCreated datePublished" datetime="2021-09-08T18:00:15+08:00">2021-09-08</time>
    </span>

  
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>2.2k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>4 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="问题现象"><a href="#问题现象" class="headerlink" title="问题现象"></a>问题现象</h1><p>  tkestack 扩容节点的步骤执行到 <code>EnsureDocker</code> 时失败，提示<code>stat provider/baremetal/res/linux-/docker-linux--19.03.9.tar.gz: no such file or directory</code></p>
<img src="/2021/09/08/Docker0%E5%AD%90%E7%BD%91%E5%86%B2%E7%AA%81%E5%AF%BC%E8%87%B4%E8%8A%82%E7%82%B9%E6%89%A9%E5%AE%B9%E5%A4%B1%E8%B4%A5/tke-node-add-failure-ensuredocker-1.png" class="" title="tke-node-add-failure-ensuredocker-1.png">

<h1 id="处理方法"><a href="#处理方法" class="headerlink" title="处理方法"></a>处理方法</h1><h2 id="错误原因"><a href="#错误原因" class="headerlink" title="错误原因"></a>错误原因</h2><p>  出现 <code>EnsureDocker</code> 故障时不一定就是物料问题导致的，docker 安装的步骤实际上是通过二进制包直接覆盖安装。所以一般情况下不大容易出错。出现该类问题可能是网络原因导致的。</p>
<p>  当出现该类错误时，应该优先确认一下网段冲突的问题，需要确认一下 <code>tke-platform-controller</code> 组件所在的节点使用了 <strong>172.17.0.0&#x2F;16</strong> 网段的地址。该地址段和 docker0 的默认子网存在冲突，会导致网络连通性异常。为什么使用该网段会对扩容步骤造成影响？</p>
<p>  下图是执行扩容步骤前的网络情况，观察 <code>tke-platform-controller</code> 的路由表我们可以看到，待扩容节点回包时通过路由选择，此时会走默认路由，从 eth0 接口出去。</p>


<p>  下图是执行扩容步骤执行 <code>EnsureDocker</code> 时的网络情况，待扩容节点由于安装了 docker，自动生成了 docker0 的网桥设备，该设备会使用 172.17.1.1&#x2F;16 这个地址，配置了该地址以后会在主机路由上自动添加一条 <strong>172.17.0.0&#x2F;16</strong> 的直连路由。</p>


<p>  添加上该路由以后，后续待扩容节点再和 <code>tke-platform-controller</code> 组件所在节点通信时，由于路由优先级，此时不会再从 eth0 回包。报文将会从 docker0 回复，但实际上通过 docker0 我们是无法与 <code>tke-platform-controller</code> 组件运行的节点进行通信的。此时 TKE 后续扩容的步骤都将无法执行。</p>
<h2 id="操作步骤"><a href="#操作步骤" class="headerlink" title="操作步骤"></a>操作步骤</h2><h3 id="确认-tke-platform-controller-组件运行的机器是否使用-172-17-0-0-16-网段"><a href="#确认-tke-platform-controller-组件运行的机器是否使用-172-17-0-0-16-网段" class="headerlink" title="确认 tke-platform-controller 组件运行的机器是否使用 172.17.0.0&#x2F;16 网段"></a>确认 tke-platform-controller 组件运行的机器是否使用 172.17.0.0&#x2F;16 网段</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">执行如下命令查询 Pod 运行的节点信息</span></span><br><span class="line">kubectl get pod -n cpaas-system -o wide | grep tke-platform-controller</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">输出示例</span></span><br><span class="line">[root@tke-192-168-0-2 ~]# kubectl get pod -n cpaas-system -o wide | grep tke-platform-controller</span><br><span class="line">tke-platform-controller-5459d9c58c-t7k5n               1/1     Running   55         24h     10.199.0.32     192.168.0.2    &lt;none&gt;           &lt;none&gt;</span><br><span class="line">tke-platform-controller-5459d9c58c-x5pqd               1/1     Running   10         2d10h   10.199.1.158    192.168.0.25   &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></table></figure>

<p>  如果明确节点使用了非 172.17.0.0&#x2F;16 网段，请<strong>提工单联系后端同学排查</strong> <code>EnsureDocker</code>失败的原因。如果节点使用了 <strong>172.17.0.0&#x2F;16</strong> 网段，可参考下面的规避方法。</p>
<h3 id="tke-platform-controller-节点使用-172-17-0-0-16-网段的规避方法"><a href="#tke-platform-controller-节点使用-172-17-0-0-16-网段的规避方法" class="headerlink" title="tke-platform-controller 节点使用 172.17.0.0&#x2F;16 网段的规避方法"></a>tke-platform-controller 节点使用 172.17.0.0&#x2F;16 网段的规避方法</h3><h4 id="方案一：通过静态路由规避"><a href="#方案一：通过静态路由规避" class="headerlink" title="方案一：通过静态路由规避"></a>方案一：通过静态路由规避</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在待扩容节点上，添加静态路由</span></span><br><span class="line">route add -net 172.17.1.0/24 gw 172.21.2.1</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">待扩容工作完成以后，修改新扩容节点的 /etc/docker/daemon.json 配置，添加 bip，修改 docker0 的地址段，注意该网段不能和客户环境其他子网地址重复。</span></span><br><span class="line">vim /etc/dockder/daemon.json</span><br><span class="line">&#123;</span><br><span class="line">    ....</span><br><span class="line">    &quot;bip&quot;:&quot;192.168.1.0/24&quot;,   # 增加 bip 配置</span><br><span class="line">    ....</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">删除临时添加的静态路由</span></span><br><span class="line">route del -net 172.17.1.0/24 gw 172.21.2.1</span><br></pre></td></tr></table></figure>

<h4 id="方案二：将-tke-platform-controller-迁移到非-172-17-0-0-16-地址段的机器上"><a href="#方案二：将-tke-platform-controller-迁移到非-172-17-0-0-16-地址段的机器上" class="headerlink" title="方案二：将 tke-platform-controller 迁移到非 172.17.0.0&#x2F;16 地址段的机器上"></a>方案二：将 tke-platform-controller 迁移到非 172.17.0.0&#x2F;16 地址段的机器上</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在 tke-platform-controller、tke-platform-api 的 deployment 中增加如下配置</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">位于 spec.template.spec 字段下</span></span><br><span class="line">nodeSelector:</span><br><span class="line">  key: value  #自定义</span><br><span class="line"></span><br><span class="line">注意，在迁移过程中，tke 的集群、机器扩容功能会暂时不可用。通常情况下我们应该尽量在交付初期确认清楚该问题。避免后续运维的扩容阶段引入风险。</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://guoltan.github.io/2021/01/21/helm%E5%85%A5%E9%97%A8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="guoltan">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="guoltan个人博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | guoltan个人博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/01/21/helm%E5%85%A5%E9%97%A8/" class="post-title-link" itemprop="url">Helm入门</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-01-21 18:00:15" itemprop="dateCreated datePublished" datetime="2021-01-21T18:00:15+08:00">2021-01-21</time>
    </span>

  
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>21k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>38 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="什么是Helm？"><a href="#什么是Helm？" class="headerlink" title="什么是Helm？"></a>什么是Helm？</h1><p>  <strong>Helm的基本定义</strong></p>
<p>  根据官网的定义，Helm 是 kubernetes 的包管理器。Helm是用于发现，分享，构建应用程序于 Kubernetes 的最佳方法。</p>
<p>  可以把 Helm 部署应用的方式比作在 centos 系统上通过 rpm 安装软件一样。使用 rpm 去安装应用时，因为软件开发者已经提前将程序打包成了一个 rpm 包。我们去部署时只需要简单的通过类 rpm -ivh xxx.rpm 来进行安装即可。免去了软件编译安装等动作。 通过 Helm 的方式部署 Kubernetes 应用也类似。 通过 Helm 我们可以把应用构建成 Chart 包。以后在其他 Kubernetes 集群上部署应用时，只需要简单的通过 Helm 进行部署，极大的简化了应用的部署成本。</p>
<p>  通过 Helm 去部署 Kubernetes 应用，可以将 deployment,svc,pvc,configmap 等等资源整合在一起。不再需要单独的进行类似kubectl apply -f resource.yaml 的动作。而是通过类 helm install stable&#x2F;nginx –set service.type&#x3D;NodePort  的动作来完成应用在  Kubernetes 环境上的部署。</p>
<p>  使用 Helm 部署 Kubernetes 资源，存在如下好处：</p>
<ul>
<li><p>可以实现统一的配置管理，通过 Helm 我们可以将分散的 Kubernetes 资源对象整合成一个整体。通过这个整体入口进行维护，简化管理。</p>
</li>
<li><p>可以实现应用模板的复用，编写好。简化后续开发成本。</p>
</li>
<li><p>简化部署和学习的成本，想要简单的部署一个应用，只需要学习 Charts 的变量以及基础的理论知识即可。不需要深入的学习配置项。</p>
<p><strong>Helm 的基本概念</strong></p>
</li>
</ul>
<table>
<thead>
<tr>
<th>术语</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>Chart</td>
<td>Kubernetes 应用实例的信息集合，本质上是一堆模板文件，根据环境对内容渲染，从而部署到 Kubernetes 集群上。开发者可以按需求制作 Chart 包。</td>
</tr>
<tr>
<td>Config</td>
<td>创建发布对象的chart的配置信息。</td>
</tr>
<tr>
<td>Release</td>
<td>Chart 的在 Kubernetes 上的运行实例。一个 Chart 可以在同一个 Kubernetes 集群上安装多次，每个实例以不同的 Release 做区分，后续通过维护 Release 状态来追踪部署的应用信息。</td>
</tr>
<tr>
<td>Repository</td>
<td>用于存储 Chart 包的仓库。</td>
</tr>
</tbody></table>
<p>  目前Helm已经发展到V3版本了。本文将统一介绍 Helm v2 和 v3 版本。</p>
<h1 id="Helm-架构"><a href="#Helm-架构" class="headerlink" title="Helm 架构"></a>Helm 架构</h1><h2 id="Helm-的逻辑架构"><a href="#Helm-的逻辑架构" class="headerlink" title="Helm 的逻辑架构"></a><strong>Helm 的逻辑架构</strong></h2><p>![image-20201204114344460](D:\My\学习\6. 笔记\3. 微服务\Helm\picture\helm.asserts\image-20201204114344460.png)</p>
<p>  Helm v2 的逻辑架构如上图，开发者可以根据自己的需求提前将资源文件(类似 svc.yaml,deployment.yaml,pvc.yaml 等等) 通过 package 打包成 Chart 包。 再将 Chart 包 upload 到 Chart Repository 上。此时各个用户就可以通过连接 Chart Repository 去获取 Chart 包了。如果这个时候有个用户想将 Chart 包的应用部署到 Kubernetes 集群上，只需要通过 <code>helm install</code>，将 Chart 包 pull 到本地，或者直接使用本地的某个 Chart 包，再通过 grpc 的方式提交请求和资源文件给 Kubernetes 集群上的 Tiller 组件。 Tiller 组件接收到请求以后，会将其解析成 apiserver 能够识别的指令，再将其提交给 apiserver 。最终让 apiserver 来完成资源的创建。最终创建出的应用会被 Helm 以 release 进行状态追踪。</p>
<p>![image-20201204115220160](D:\My\学习\6. 笔记\3. 微服务\Helm\picture\helm.asserts\image-20201204115220160.png)</p>
<p>  Helm v3 的逻辑架构和 Helm v2 基本一致，它去除了 tiller 组件。直接调用 kube-config 中的配置信息，对集群上资源进行创建和管理。</p>
<h2 id="Helm-v2-与-Helm-v3-的区别"><a href="#Helm-v2-与-Helm-v3-的区别" class="headerlink" title="Helm v2 与 Helm v3 的区别"></a><strong>Helm v2 与 Helm v3 的区别</strong></h2><p>  Helm v3 去除了 tiller 组件实现了 client-only 架构。使得使用 Helm 进行安装部署更加简单</p>
<p>  Helm v3 的 release 现在存储在集群的资源对象替换成了 secret。</p>
<p>  Helm v3 的 release 持久化存储在 release 所运行的命名空间下。而不是固定存放在 kube-system。 这使得它能够支持 release 跨命名空间重名。</p>
<p>  Helm v3 向下兼容 Helm v2，Helm v3 支持渲染 v2 的 Chart。</p>
<p>  Helm v3 增加了对 values.yaml 的校验。</p>
<p>  Helm v3 对一部分 v2 的命令进行了替换和删除。</p>
<h1 id="如何使用Helm？"><a href="#如何使用Helm？" class="headerlink" title="如何使用Helm？"></a><strong>如何使用Helm？</strong></h1><p>  了解到 Helm 的逻辑架构以及业务流以后，我们知道，想要使用 Helm 大概需要做如下的事情：</p>
<ul>
<li>获取 Helm 的部署包。</li>
<li>Helm 需要安装客户端，客户端用于提交和下载 Chart 包。</li>
<li>在使用 Helm v2 时，需要部署 Tiller 组件，它运行在 Kubernetes 集群之上，并且需要访问 Apiserver 申请资源。我们需要在 Kubernetes 部署 Tiller 组件，并且还需要给他配置 RBAC 角色。</li>
<li>我们需要一个 REPOSITORY 的组件用于存储 Chart。</li>
</ul>
<h2 id="使用-Helm-v2"><a href="#使用-Helm-v2" class="headerlink" title="使用 Helm v2"></a>使用 Helm v2</h2><h3 id="获取-Helm-v2-的部署包"><a href="#获取-Helm-v2-的部署包" class="headerlink" title="获取 Helm v2 的部署包"></a>获取 Helm v2 的部署包</h3><p>  通过 Github 可以获取最新的 Helm 安装包，链接： <a target="_blank" rel="noopener" href="https://github.com/helm/helm/releases%E3%80%82">https://github.com/helm/helm/releases。</a> 由于 GitHub 在外网，在国内访问速度比较慢。笔者将 Helm 包最新的版本下载到本地，并上传到网盘。可以直接获取。获取链接：链接：<a target="_blank" rel="noopener" href="https://pan.baidu.com/s/12SgVFA0PpsQB_98NjwiOzA">https://pan.baidu.com/s/12SgVFA0PpsQB_98NjwiOzA</a>  提取码：Helm </p>
<h3 id="安装-Helm-v2-部署包"><a href="#安装-Helm-v2-部署包" class="headerlink" title="安装 Helm v2 部署包"></a>安装 Helm v2 部署包</h3><p>  将获取到的 helm-v2.16.9-linux-amd64.tar.gz 上传到 Kubernetes 集群机器上。并执行如下动作进行安装</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tar xvf helm-v2.16.9-linux-amd64.tar.gz</span><br><span class="line"></span><br><span class="line">cp -p linux-amd64/helm /usr/local/bin</span><br></pre></td></tr></table></figure>

<p>  执行完成以后通过 helm version 检验是否已经安装上</p>
<p>![image-20201130104508620](D:\My\学习\6. 笔记\3. 微服务\k8s\note_picture\helm.asserts\image-20201130104508620.png)</p>
<p>  此时会提示 <code>Error: could not find a ready tiller pod</code> 表示 tiller 组件未能正确找到。这个时候还需要通过 helm init 去初始化安装 tiller。</p>
<p>  因为 Kubernetes 1.13 加入了 RBAC 的授权机制，我们需要提前为 tiller 创建 service account。后续才能正常的使用。执行如下命令创建</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl create serviceaccount --namespace kube-system tiller</span><br><span class="line">kubectl create clusterrolebinding tiller-cluster-rule --clusterrole=cluster-admin --serviceaccount=kube-system:tiller</span><br></pre></td></tr></table></figure>

<p>  此时通过 helm init 对环境进行初始化，默认会添加 google 的 helm 仓库，使用海外的 tiller 镜像。当前是国内环境，直接拉取海外的镜像源会非常缓慢，所以我们需要手工添加 <code>--stable-repo-url</code> 参数，设置使用国内的 helm 仓库源。添加 <code> --tiller-image</code> 参数，设置 tiller 镜像路径为国内镜像的仓库路径。并通过<code>--service-account</code> 参数指定创建的  service account。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">helm init --tiller-image registry.cn-hangzhou.aliyuncs.com/google_containers/tiller:v2.16.9 --stable-repo-url https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts --service-account tiller</span><br></pre></td></tr></table></figure>

<blockquote>
<p>  注意：如果没有为 tiller 创建 service account ，部署完成以后，执行 helm ls 等需要调用 kubernetes 资源的命令时，会提示如下报错。</p>
</blockquote>
<p><img src="C:\Users\89715\AppData\Roaming\Typora\typora-user-images\image-20201202170301217.png" alt="image-20201202170301217"></p>
<p> 部署完成以后，通过<code> helm ls</code> 来确认基本功能是否正常，此时我们的 kubernetes 集群上并没有部署任何的 Chart 所以返回为空是正常的。</p>
<p><img src="C:\Users\89715\AppData\Roaming\Typora\typora-user-images\image-20201202173915143.png" alt="image-20201202173915143"> </p>
<p>通过 helm repo list 命令，我们可以查询到，当前拥有两个 helm 仓库，分别是 stable 和 local。 stable对应的就是我们在部署中添加的 阿里云仓库路径。</p>
<p><img src="C:\Users\89715\AppData\Roaming\Typora\typora-user-images\image-20201202174245350.png" alt="image-20201202174245350"></p>
<p>此时可以通过 helm search Chart 包名称，来获取仓库上的 Chart 包。</p>
<p><img src="C:\Users\89715\AppData\Roaming\Typora\typora-user-images\image-20201202174434422.png" alt="image-20201202174434422"></p>
<h3 id="使用-Helm-部署一个应用"><a href="#使用-Helm-部署一个应用" class="headerlink" title="使用 Helm 部署一个应用"></a>使用 Helm 部署一个应用</h3><p>  现在已经成功的安装上 Helm ，也可以从 Helm 仓库中获取 Chart 包。接下来我将使用 myapp-1.0.0.tgz 这个包作为演示，将该应用部署到 Kubernetes 集群上。</p>
<p>  通过 <code>helm install myapp-1.0.0.tgz --name myapp</code> 命令，将该 Chart 包部署到 Kubernetes 集群上。</p>
<p>![image-20201203145511844](D:\My\学习\6. 笔记\3. 微服务\Helm\picture\helm.asserts\image-20201203145511844.png)</p>
<p>  此时可以看到，helm 会打印本次部署 myapp-1.0.0.tgz 创建了哪些资源。以及访问该应用的简单示例。根据 NOTES 打印的示例，测试该应用。</p>
<p>![image-20201203181459561](D:\My\学习\6. 笔记\3. 微服务\Helm\picture\helm.asserts\image-20201203181459561.png)</p>
<p>  从上图可以看到的是，根据 NOTES 提供的测试方法，可以正确的访问该应用。</p>
<h3 id="Chart-包的目录结构"><a href="#Chart-包的目录结构" class="headerlink" title="Chart 包的目录结构"></a>Chart 包的目录结构</h3><p>  接下来我们看一下 Chart 包中实际打包了哪些东西。它的内部结构是怎么样的。将 myapp-1.0.0.tgz 包进行解压，通过 <code>tar xvf myapp-1.0.0.tgz</code> 来完成。再通过 <code>tree</code> 查看具体内容。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">├── Chart.yaml                         # 用于描述 Chart 的基本信息                </span><br><span class="line">├── templates                         # 该目录上存放的 Chart 是待渲染的模板文件，通过 values.yaml 对内容进行渲染。</span><br><span class="line">│   ├── deployment.yaml             # deployment 资源模板</span><br><span class="line">│   ├── _helpers.tpl                 # 模板帮助器，通常存放全局可重用的变量，根据判断条件生成对应变量的值</span><br><span class="line">│   ├── ingress.yaml                 # ingress 资源模板</span><br><span class="line">│   ├── NOTES.txt                     # Chart的使用说明，在 helm install 以后会自动输出的说明内容</span><br><span class="line">│   ├── serviceaccount.yaml         # service account 资源模板</span><br><span class="line">│   ├── service.yaml                # service 资源模板</span><br><span class="line">│   └── tests                         # 该目录上存放的 Chart 的测试用例，通过 helm test 可以调用</span><br><span class="line">│       └── test-connection.yaml    # 测试用例</span><br><span class="line">└── values.yaml                        # 该文件存储了 Chart 资源清单中使用的默认值，后续会渲染到 templates 的资源模板上。</span><br></pre></td></tr></table></figure>

<p>  接下来查看 Chart 包中文件的具体内容，通过 <code>cat Chart.yaml </code> 可以看到 Chart.yaml 中有 <code>apiVersion</code> 、 <code>appVersion</code> 、 <code>description</code> 、 <code>name</code> 等字段。主要的内容是描述这个 Chart 包可以干什么，对应的 app 版本，我们在 helm search 的时候查询 Chart 包时，有关包描述的信息就是此处。</p>
<p>![image-20201203151340282](D:\My\学习\6. 笔记\3. 微服务\Helm\picture\helm.asserts\image-20201203151340282.png)</p>
<p>  查看 values.yaml 的详细内容，该文件的内容用于渲染 templates 下的模板文件。像是我们对应用部署出的副本数有需求，比如需要使用 3 副本。 或者使用的镜像源来自于某个仓库。这些相对固定的字段都可以在该文件中定义，后续在渲染的时候就可以直接采用这些值进行填充。</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Default values for myapp.</span></span><br><span class="line"><span class="comment"># This is a YAML-formatted file.</span></span><br><span class="line"><span class="comment"># Declare variables to be passed into your templates.</span></span><br><span class="line"></span><br><span class="line"><span class="attr">replicaCount:</span> <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="attr">image:</span></span><br><span class="line">  <span class="attr">repository:</span> <span class="string">daocloud.io/nginx</span></span><br><span class="line">  <span class="attr">tag:</span> <span class="string">latest</span></span><br><span class="line">  <span class="attr">pullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line"></span><br><span class="line"><span class="attr">service:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">ClusterIP</span></span><br><span class="line">  <span class="attr">port:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>

<p>  我们可以通过查询 templates&#x2F;deployment.yaml 来查看 values.yaml 里面定义的值是如何渲染到资源模板的。如下所示，我们可以看到像是 <code>replicas: &#123;&#123; .Values.replicaCount &#125;&#125;</code> 这类的字段，代表副本数的具体定义通过 values.yaml 文件来获取。而 <code>&#123;&#123; include "myapp.labels" . &#125;&#125; </code> 这类的字段则是引用 _helpers.tpl 文件中定义的 <code>myapp.name</code> 变量的值。 </p>
<p>  include 和 template 都可以用于引用变量。但通过 template 导入变量内容时无法统一对数据进行格式化，所以通常会使用 include 来引入。 </p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> &#123;&#123; <span class="string">include</span> <span class="string">&quot;myapp.fullname&quot;</span> <span class="string">.</span> &#125;&#125;</span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">&#123;&#123; <span class="string">include</span> <span class="string">&quot;myapp.labels&quot;</span> <span class="string">.</span> <span class="string">|</span> <span class="string">indent</span> <span class="number">4</span> &#125;&#125;</span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> &#123;&#123; <span class="string">.Values.replicaCount</span> &#125;&#125;</span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app.kubernetes.io/name:</span> &#123;&#123; <span class="string">template</span> <span class="string">&quot;myapp.name&quot;</span> <span class="string">.</span> &#125;&#125;</span><br><span class="line">      <span class="attr">app.kubernetes.io/instance:</span> &#123;&#123; <span class="string">.Release.Name</span> &#125;&#125;</span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app.kubernetes.io/name:</span> &#123;&#123; <span class="string">template</span> <span class="string">&quot;myapp.name&quot;</span> <span class="string">.</span> &#125;&#125;</span><br><span class="line">        <span class="attr">app.kubernetes.io/instance:</span> &#123;&#123; <span class="string">.Release.Name</span> &#125;&#125;</span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> &#123;&#123; <span class="string">.Chart.Name</span> &#125;&#125;</span><br><span class="line">          <span class="attr">image:</span> <span class="string">&quot;<span class="template-variable">&#123;&#123; .Values.image.repository &#125;&#125;</span>:<span class="template-variable">&#123;&#123; .Values.image.tag &#125;&#125;</span>&quot;</span></span><br><span class="line">          <span class="attr">imagePullPolicy:</span> &#123;&#123; <span class="string">.Values.image.pullPolicy</span> &#125;&#125;</span><br><span class="line">          <span class="attr">lifecycle:</span></span><br><span class="line">            <span class="attr">postStart:</span></span><br><span class="line">              <span class="attr">exec:</span></span><br><span class="line">                <span class="attr">command:</span></span><br><span class="line">                <span class="bullet">-</span> <span class="string">/bin/sh</span></span><br><span class="line">                <span class="bullet">-</span> <span class="string">-c</span></span><br><span class="line">                <span class="bullet">-</span> <span class="string">echo</span> <span class="string">Hello,</span> <span class="string">this</span> <span class="string">is</span> <span class="string">helm</span> <span class="string">example</span> <span class="string">app,</span> <span class="string">version</span> <span class="string">is</span> <span class="string">&quot;<span class="template-variable">&#123;&#123; .Chart.Version &#125;&#125;</span>&quot;</span><span class="string">.</span>  <span class="string">&gt;</span> <span class="string">/usr/share/nginx/html/index.html</span></span><br><span class="line">          <span class="attr">ports:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span></span><br><span class="line">              <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">              <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">          <span class="attr">livenessProbe:</span></span><br><span class="line">            <span class="attr">httpGet:</span></span><br><span class="line">              <span class="attr">path:</span> <span class="string">/</span></span><br><span class="line">              <span class="attr">port:</span> <span class="string">http</span></span><br><span class="line">          <span class="attr">readinessProbe:</span></span><br><span class="line">            <span class="attr">httpGet:</span></span><br><span class="line">              <span class="attr">path:</span> <span class="string">/</span></span><br><span class="line">              <span class="attr">port:</span> <span class="string">http</span></span><br></pre></td></tr></table></figure>

<p>  查看 templates&#x2F;_helpers.tpl 文件的内容，可以看到文件的内容是定义各种可重用的变量。这些变量的值会根据各种条件生成。</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#123;<span class="comment">/* vim: set filetype=mustache: */</span>&#125;&#125;</span><br><span class="line">&#123;&#123;<span class="comment">/*</span></span><br><span class="line"><span class="comment">Expand the name of the chart.</span></span><br><span class="line"><span class="comment">*/</span>&#125;&#125;</span><br><span class="line">&#123;&#123;- define <span class="string">&quot;myapp.name&quot;</span> -&#125;&#125;</span><br><span class="line">&#123;&#123;- <span class="keyword">default</span> .Chart.Name .Values.nameOverride | trunc <span class="number">63</span> | trimSuffix <span class="string">&quot;-&quot;</span> -&#125;&#125;</span><br><span class="line">&#123;&#123;- end -&#125;&#125;</span><br><span class="line"></span><br><span class="line">&#123;&#123;<span class="comment">/*</span></span><br><span class="line"><span class="comment">Create a default fully qualified app name.</span></span><br><span class="line"><span class="comment">We truncate at 63 chars because some Kubernetes name fields are limited to this (by the DNS naming spec).</span></span><br><span class="line"><span class="comment">If release name contains chart name it will be used as a full name.</span></span><br><span class="line"><span class="comment">*/</span>&#125;&#125;</span><br><span class="line">&#123;&#123;- define <span class="string">&quot;myapp.fullname&quot;</span> -&#125;&#125;</span><br><span class="line">&#123;&#123;- <span class="keyword">if</span> .Values.fullnameOverride -&#125;&#125;</span><br><span class="line">&#123;&#123;- .Values.fullnameOverride | trunc <span class="number">63</span> | trimSuffix <span class="string">&quot;-&quot;</span> -&#125;&#125;</span><br><span class="line">&#123;&#123;- <span class="keyword">else</span> -&#125;&#125;</span><br><span class="line">&#123;&#123;- $name := <span class="keyword">default</span> .Chart.Name .Values.nameOverride -&#125;&#125;</span><br><span class="line">&#123;&#123;- <span class="keyword">if</span> contains $name .Release.Name -&#125;&#125;</span><br><span class="line">&#123;&#123;- .Release.Name | trunc <span class="number">63</span> | trimSuffix <span class="string">&quot;-&quot;</span> -&#125;&#125;</span><br><span class="line">&#123;&#123;- <span class="keyword">else</span> -&#125;&#125;</span><br><span class="line">&#123;&#123;- printf <span class="string">&quot;%s-%s&quot;</span> .Release.Name $name | trunc <span class="number">63</span> | trimSuffix <span class="string">&quot;-&quot;</span> -&#125;&#125;</span><br><span class="line">&#123;&#123;- end -&#125;&#125;</span><br><span class="line">&#123;&#123;- end -&#125;&#125;</span><br><span class="line">&#123;&#123;- end -&#125;&#125;</span><br></pre></td></tr></table></figure>

<p>  查看 templates&#x2F;NOTES.txt 的内容，可以看到这些内容对应的是 <code>helm install </code> 执行时产生的信息。该文件的内容通常用于提示用户如何访问应用。或者补充 Chart 的一些相关信息。</p>
<p>![image-20201203181459561](D:\My\学习\6. 笔记\3. 微服务\Helm\picture\helm.asserts\image-20201203181459561.png)</p>
<p>  查看 templates&#x2F;test&#x2F;test-connection.yaml 文件的内容， 这个资源文件是给 <code>helm test</code> 功能准备的，我们可以通过执行 <code>helm test releasename </code> 来执行该文件中的动作。我们可以将一些测试方法提前写好。用户通过该方法即可验证应用是否可正常使用。 在这里test-connection.yaml 的内容是用于创建一个 Pod 并执行 wget 命令，测试服务的连通性是否正常。 </p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">&quot;<span class="template-variable">&#123;&#123; include &quot;myapp.fullname&quot; . &#125;&#125;</span>-test-connection&quot;</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">&#123;&#123; <span class="string">include</span> <span class="string">&quot;myapp.labels&quot;</span> <span class="string">.</span> <span class="string">|</span> <span class="string">indent</span> <span class="number">4</span> &#125;&#125;</span><br><span class="line">  <span class="attr">annotations:</span></span><br><span class="line">    <span class="attr">&quot;helm.sh/hook&quot;:</span> <span class="string">test-success</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">wget</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">busybox</span></span><br><span class="line">      <span class="attr">command:</span> [<span class="string">&#x27;wget&#x27;</span>]</span><br><span class="line">      <span class="attr">args:</span>  [<span class="string">&#x27;<span class="template-variable">&#123;&#123; include &quot;myapp.fullname&quot; . &#125;&#125;</span>:<span class="template-variable">&#123;&#123; .Values.service.port &#125;&#125;</span>&#x27;</span>]</span><br><span class="line">  <span class="attr">restartPolicy:</span> <span class="string">Never</span></span><br></pre></td></tr></table></figure>

<h3 id="release-的版本控制"><a href="#release-的版本控制" class="headerlink" title="release 的版本控制"></a>release 的版本控制</h3><h4 id="体验版本控制"><a href="#体验版本控制" class="headerlink" title="体验版本控制"></a>体验版本控制</h4><p>  之前提到过，通过 helm 部署的应用会以 release 的形式记录。以追踪它在集群的状态。现在我们对 release 版本进行一次升级。替换 Charts.yaml，将 <code>version 1.0.0</code> 替换为 <code>version 2.0.0</code> 。然后重新执行 <code>helm upgrade release_name chart_path</code> 进行版本升级。（如果不指定 –version 选项，默认升级到最新版本。）</p>
<p>![image-20201203175511136](D:\My\学习\6. 笔记\3. 微服务\Helm\picture\helm.asserts\image-20201203175511136.png)</p>
<p>  此时发现 <code>REVISION</code> 的字段变成了 2，并且<code>CHART</code> 字段也变成了 myapp-2.0.0 </p>
<p>![image-20201203175537768](D:\My\学习\6. 笔记\3. 微服务\Helm\picture\helm.asserts\image-20201203175537768.png)</p>
<p>  通过 curl 命令进行测试，此时可以看到网页输出的内容也改变了。</p>
<p>![image-20201203181956303](D:\My\学习\6. 笔记\3. 微服务\Helm\picture\helm.asserts\image-20201203181956303.png)</p>
<p>  此时我们可以通过 <code>helm history myapp</code> 来获取该 release 的历史版本 可以看到这个 release 的历史记录。 <code>REVISION</code> 代表版本号，该值会随着 Release 的迭代而增加，<code>STATUS</code> 代表当前 Release 的状态，DEPLOYED 代表当前已经部署上。 <code>DESCRIPTION</code> 则是用于表示该版本是通过什么动作产生的。</p>
<p>![image-20201203182227355](D:\My\学习\6. 笔记\3. 微服务\Helm\picture\helm.asserts\image-20201203182227355.png)</p>
<p>  如果我们希望回退到其中一个版本，可以执行 <code>helm rollback release_name revision</code> 进行版本回滚。现在通过 <code>helm rollback myapp 1</code> 进行版本回退。回退结束后，通过<code>helm history myapp</code> 可以查询有新的 REVISION 版本生成。</p>
<p>![image-20201203182938211](D:\My\学习\6. 笔记\3. 微服务\Helm\picture\helm.asserts\image-20201203182938211.png)</p>
<p>  回滚结束以后，进行页面访问测试，可以查看页面访问的版本</p>
<p>![image-20201204104837523](D:\My\学习\6. 笔记\3. 微服务\Helm\picture\helm.asserts\image-20201204104837523.png)</p>
<h4 id="版本控制是如何实现的"><a href="#版本控制是如何实现的" class="headerlink" title="版本控制是如何实现的"></a>版本控制是如何实现的</h4><p>  我们知道 helm 通过 release 来实现版本控制的。具体是如何做到的呢？ 实际上我们在进行 <code>helm install </code> 或者 <code>helm upgrade</code> 的时候，每当 release 的版本发生改变，都会在 kube-system 命名空间下新建一个 configmap。通过 <code>kubectl get cm -n kube-system -l &quot;OWNER=TILLER&quot; </code> 命令来获取这些 configmap。</p>
<p>![image-20201204103012259](D:\My\学习\6. 笔记\3. 微服务\Helm\picture\helm.asserts\image-20201204103012259.png)</p>
<p>  编辑其中一个版本，查看其中配置的内容。可以看到该 configmap 存储了 release 的数据。因为有这个 configmap 文件在，所以 helm 才能追踪 release 在集群上的版本。实现版本控制。</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">release:</span> <span class="string">H4sIAAAAAAAC...</span>  <span class="comment"># 内容过多，省略，该处是用于存储 release 的 yaml 资源配置。可通过 base64 + gzip 解码</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">creationTimestamp:</span> <span class="string">&quot;2020-12-02T23:36:10Z&quot;</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">MODIFIED_AT:</span> <span class="string">&quot;1606952476&quot;</span></span><br><span class="line">    <span class="attr">NAME:</span> <span class="string">myapp</span></span><br><span class="line">    <span class="attr">OWNER:</span> <span class="string">TILLER</span></span><br><span class="line">    <span class="attr">STATUS:</span> <span class="string">SUPERSEDED</span></span><br><span class="line">    <span class="attr">VERSION:</span> <span class="string">&quot;1&quot;</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">myapp.v1</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line">  <span class="attr">resourceVersion:</span> <span class="string">&quot;1975523&quot;</span></span><br><span class="line">  <span class="attr">selfLink:</span> <span class="string">/api/v1/namespaces/kube-system/configmaps/myapp.v1</span></span><br><span class="line">  <span class="attr">uid:</span> <span class="string">0705b870-4d16-4255-bfdc-a97dc3a0e043</span></span><br></pre></td></tr></table></figure>

<p>  像是 <code>helm ls</code> 其实就是通过 <code>kubectl get cm -n kube-system -l OWNER=TILLER,STATUS=DEPLOYED</code> 来实现查询的，而 <code>helm history myapp</code> 则是通过 <code>kubectl get cm -n kube-system -l OWNER=TILLER,NAME=myapp</code> 来查询。通过访问这些 configmap 信息，来完成对 release 的追踪。</p>
<p>![image-20201204104602146](D:\My\学习\6. 笔记\3. 微服务\Helm\picture\helm.asserts\image-20201204104602146.png)</p>
<h2 id="使用-Helm-v3"><a href="#使用-Helm-v3" class="headerlink" title="使用 Helm v3"></a>使用 Helm v3</h2><h3 id="安装-Helm-v3-部署包"><a href="#安装-Helm-v3-部署包" class="headerlink" title="安装 Helm v3 部署包"></a>安装 Helm v3 部署包</h3><p>  将软件包上传到环境，执行如下命令，进行 Helm v3 版本的部署。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">解压软件包</span></span><br><span class="line">tar xvf helm-v3.4.1-linux-amd64.tar.gz</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">拷贝 helm 程序到环境，考虑到后续需要进行Helm v2 到 Helm v3 的迁移。暂时不替换 helm 命令。将其重命名为 helmv3。</span></span><br><span class="line">cp linux-amd64/helm /usr/local/bin/helmv3</span><br></pre></td></tr></table></figure>

<p>  执行 <code>helmv3 ls</code> 测试 Helm v3 组件的运作。</p>
<p>![image-20201204110802877](D:\My\学习\6. 笔记\3. 微服务\Helm\picture\helm.asserts\image-20201204110802877.png)</p>
<h3 id="执行-Helm-v2-迁移到-Helm-v3-版本的工作"><a href="#执行-Helm-v2-迁移到-Helm-v3-版本的工作" class="headerlink" title="执行 Helm v2 迁移到 Helm v3 版本的工作"></a>执行 Helm v2 迁移到 Helm v3 版本的工作</h3><p>  Helm v3 的操作方法和 Helm v2 基本上大同小异，我们现在执行一项动作，将当前 Helm v2 部署的 release 以及环境配置迁移到 Helm v3 环境。该项工作可以使用 Helm 社区提供的 helm 2to3 插件来进行。将 helm-2to3-master 目录上传到环境，执行插件安装。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">helmv3 plugin install https://github.com/helm/helm-2to3</span><br><span class="line">helmv3 plugin list</span><br></pre></td></tr></table></figure>

<p>  2to3 插件目前提供了三个可用的选项，一个是 convert ，它用于实现 Helm v2 的 release 迁移到 Helm v3 环境。 另一个是 move ， 它用于实现 helm 配置的迁移。将 Helm 的配置文件进行搬迁。以及 cleanup 用于清理 Helm v2 的数据。（包括 tiller，release configmap等）</p>
<p><strong>执行配置迁移</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">执行配置迁移</span></span><br><span class="line">[root@k8s-master ~]# helmv3 2to3 move config</span><br><span class="line">2020/12/04 11:50:50 WARNING: Helm v3 configuration may be overwritten during this operation.</span><br><span class="line">2020/12/04 11:50:50</span><br><span class="line">[Move config/confirm] Are you sure you want to move the v2 configuration? [y/N]: y</span><br><span class="line">2020/12/04 11:50:51</span><br><span class="line">Helm v2 configuration will be moved to Helm v3 configuration.</span><br><span class="line">2020/12/04 11:50:51 [Helm 2] Home directory: /root/.helm</span><br><span class="line">2020/12/04 11:50:51 [Helm 3] Config directory: /root/.config/helm</span><br><span class="line">2020/12/04 11:50:51 [Helm 3] Data directory: /root/.local/share/helm</span><br><span class="line">2020/12/04 11:50:51 [Helm 3] Cache directory: /root/.cache/helm</span><br><span class="line">2020/12/04 11:50:51 [Helm 3] Create config folder &quot;/root/.config/helm&quot; .</span><br><span class="line">2020/12/04 11:50:51 [Helm 3] Config folder &quot;/root/.config/helm&quot; created.</span><br><span class="line">2020/12/04 11:50:51 [Helm 2] repositories file &quot;/root/.helm/repository/repositories.yaml&quot; will copy to [Helm 3] config folder &quot;/root/.config/helm/repositories.yaml&quot; .</span><br><span class="line">2020/12/04 11:50:51 [Helm 2] repositories file &quot;/root/.helm/repository/repositories.yaml&quot; copied successfully to [Helm 3] config folder &quot;/root/.config/helm/repositories.yaml&quot; .</span><br><span class="line">2020/12/04 11:50:51 [Helm 3] Create cache folder &quot;/root/.cache/helm&quot; .</span><br><span class="line">2020/12/04 11:50:51 [Helm 3] cache folder &quot;/root/.cache/helm&quot; created.</span><br><span class="line">2020/12/04 11:50:51 [Helm 3] Create data folder &quot;/root/.local/share/helm&quot; .</span><br><span class="line">2020/12/04 11:50:51 [Helm 3] data folder &quot;/root/.local/share/helm&quot; created.</span><br><span class="line">2020/12/04 11:50:51 [Helm 2] starters &quot;/root/.helm/starters&quot; will copy to [Helm 3] data folder &quot;/root/.local/share/helm/starters&quot; .</span><br><span class="line">2020/12/04 11:50:51 [Helm 2] starters &quot;/root/.helm/starters&quot; copied successfully to [Helm 3] data folder &quot;/root/.local/share/helm/starters&quot; .</span><br><span class="line">2020/12/04 11:50:51 Helm v2 configuration was moved successfully to Helm v3 configuration.</span><br></pre></td></tr></table></figure>

<p><strong>执行 release 迁移</strong></p>
<p>  再接着，我们将 Helm v2 的 release 信息迁移到 Helm v3 环境上。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master ~]# helmv3 2to3 convert myapp</span><br><span class="line">2020/12/04 11:57:35 Release &quot;myapp&quot; will be converted from Helm v2 to Helm v3.</span><br><span class="line">2020/12/04 11:57:35 [Helm 3] Release &quot;myapp&quot; will be created.</span><br><span class="line">2020/12/04 11:57:35 [Helm 3] ReleaseVersion &quot;myapp.v1&quot; will be created.</span><br><span class="line">2020/12/04 11:57:35 [Helm 3] ReleaseVersion &quot;myapp.v1&quot; created.</span><br><span class="line">2020/12/04 11:57:35 [Helm 3] ReleaseVersion &quot;myapp.v2&quot; will be created.</span><br><span class="line">2020/12/04 11:57:35 [Helm 3] ReleaseVersion &quot;myapp.v2&quot; created.</span><br><span class="line">2020/12/04 11:57:35 [Helm 3] ReleaseVersion &quot;myapp.v3&quot; will be created.</span><br><span class="line">2020/12/04 11:57:35 [Helm 3] ReleaseVersion &quot;myapp.v3&quot; created.</span><br><span class="line">2020/12/04 11:57:35 [Helm 3] Release &quot;myapp&quot; created.</span><br><span class="line">2020/12/04 11:57:35 Release &quot;myapp&quot; was converted successfully from Helm v2 to Helm v3.</span><br><span class="line">2020/12/04 11:57:35 Note: The v2 release information still remains and should be removed to avoid conflicts with the migrated v3 release.</span><br><span class="line">2020/12/04 11:57:35 v2 release information should only be removed using `helm 2to3` cleanup and when all releases have been migrated over.</span><br></pre></td></tr></table></figure>

<p>  在 myapp 部署对应的命名空间下，通过 <code>kubectl get secret -l owner=helm</code> 命令进行查询，可以看到已经创建出对应 release 的 secret 配置。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master ~]# kubectl get secret -l owner=helm</span><br><span class="line">NAME                          TYPE                 DATA   AGE</span><br><span class="line">sh.helm.release.v1.myapp.v1   helm.sh/release.v1   1      2m11s</span><br><span class="line">sh.helm.release.v1.myapp.v2   helm.sh/release.v1   1      2m11s</span><br><span class="line">sh.helm.release.v1.myapp.v3   helm.sh/release.v1   1      2m11s</span><br></pre></td></tr></table></figure>

<p>  此时我们执行 <code>helm ls</code> 会发现，release 信息依旧可以获取到，这是因为 helm v2 的环境信息并没有被清理。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master ~]# helmv3 ls</span><br><span class="line">NAME    NAMESPACE       REVISION        UPDATED                                 STATUS          CHART           APP VERSION</span><br><span class="line">myapp   default         3               2020-12-02 23:53:07.500259911 +0000 UTC deployed        myapp-1.0.0     1.0</span><br><span class="line">[root@k8s-master ~]# helm ls</span><br><span class="line">NAME    REVISION        UPDATED                         STATUS          CHART           APP VERSION     NAMESPACE</span><br><span class="line">myapp   3               Thu Dec  3 07:53:07 2020        DEPLOYED        myapp-1.0.0     1.0             default</span><br></pre></td></tr></table></figure>

<p>  执行 <code>helmv3 2to3 cleanup</code> 可以对 helm v2 之前的数据进行清理。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master ~]# helmv3 2to3 cleanup</span><br><span class="line">WARNING: &quot;Helm v2 Configuration&quot; &quot;Release Data&quot; &quot;Tiller&quot; will be removed.</span><br><span class="line">This will clean up all releases managed by Helm v2. It will not be possible to restore them if you haven&#x27;t made a backup of the releases.</span><br><span class="line">Helm v2 may not be usable afterwards.</span><br><span class="line"></span><br><span class="line">[Cleanup/confirm] Are you sure you want to cleanup Helm v2 data? [y/N]: y</span><br><span class="line">2020/12/04 12:04:35</span><br><span class="line">Helm v2 data will be cleaned up.</span><br><span class="line">2020/12/04 12:04:35 [Helm 2] Releases will be deleted.</span><br><span class="line">2020/12/04 12:04:35 [Helm 2] ReleaseVersion &quot;myapp.v1&quot; will be deleted.</span><br><span class="line">2020/12/04 12:04:35 [Helm 2] ReleaseVersion &quot;myapp.v1&quot; deleted.</span><br><span class="line">2020/12/04 12:04:35 [Helm 2] ReleaseVersion &quot;myapp.v2&quot; will be deleted.</span><br><span class="line">2020/12/04 12:04:35 [Helm 2] ReleaseVersion &quot;myapp.v2&quot; deleted.</span><br><span class="line">2020/12/04 12:04:35 [Helm 2] ReleaseVersion &quot;myapp.v3&quot; will be deleted.</span><br><span class="line">2020/12/04 12:04:35 [Helm 2] ReleaseVersion &quot;myapp.v3&quot; deleted.</span><br><span class="line">2020/12/04 12:04:35 [Helm 2] Releases deleted.</span><br><span class="line">2020/12/04 12:04:35 [Helm 2] Tiller in &quot;kube-system&quot; namespace will be removed.</span><br><span class="line">2020/12/04 12:04:35 [Helm 2] Tiller &quot;deploy&quot; in &quot;kube-system&quot; namespace will be removed.</span><br><span class="line">2020/12/04 12:04:35 [Helm 2] Tiller &quot;deploy&quot; in &quot;kube-system&quot; namespace was removed successfully.</span><br><span class="line">2020/12/04 12:04:35 [Helm 2] Tiller &quot;service&quot; in &quot;kube-system&quot; namespace will be removed.</span><br><span class="line">2020/12/04 12:04:36 [Helm 2] Tiller &quot;service&quot; in &quot;kube-system&quot; namespace was removed successfully.</span><br><span class="line">2020/12/04 12:04:36 [Helm 2] Tiller in &quot;kube-system&quot; namespace was removed.</span><br><span class="line">2020/12/04 12:04:36 [Helm 2] Home folder &quot;/root/.helm&quot; will be deleted.</span><br><span class="line">2020/12/04 12:04:36 [Helm 2] Home folder &quot;/root/.helm&quot; deleted.</span><br><span class="line">2020/12/04 12:04:36 Helm v2 data was cleaned up successfully.</span><br></pre></td></tr></table></figure>

<h1 id="Helm的常用命令集合"><a href="#Helm的常用命令集合" class="headerlink" title="Helm的常用命令集合"></a>Helm的常用命令集合</h1><p>  有关 Helm 命令的常用说明</p>
<table>
<thead>
<tr>
<th>选项</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>create</td>
<td>创建 Chart 开发模板</td>
</tr>
<tr>
<td>env</td>
<td>打印 Helm client 的环境信息</td>
</tr>
<tr>
<td>plugin</td>
<td>管理 Helm plugin 功能</td>
</tr>
<tr>
<td>get</td>
<td>获取 Release 信息</td>
</tr>
<tr>
<td>status</td>
<td>显示 Release 的资源在集群中的状态</td>
</tr>
<tr>
<td>test</td>
<td>执行 Release 的测试用例</td>
</tr>
<tr>
<td>install</td>
<td>安装 Chart 包</td>
</tr>
<tr>
<td>upgrade</td>
<td>升级 Release 版本</td>
</tr>
<tr>
<td>rollback</td>
<td>回退 Release 版本</td>
</tr>
<tr>
<td>uninstall</td>
<td>删除 Release 版本</td>
</tr>
<tr>
<td>history</td>
<td>列出 Release 的历史版本</td>
</tr>
<tr>
<td>package</td>
<td>将某目录打包为 Chart 包</td>
</tr>
<tr>
<td>lint</td>
<td>检查 Chart 模板语法是否合规</td>
</tr>
<tr>
<td>repo</td>
<td>管理 Chart 仓库</td>
</tr>
<tr>
<td>pull</td>
<td>将 Chart 包下载到本地</td>
</tr>
<tr>
<td>search</td>
<td>在 Chart 仓库中搜索匹配条件的 Chart 包</td>
</tr>
<tr>
<td>show</td>
<td>显示某个 Chart 的信息</td>
</tr>
<tr>
<td>version</td>
<td>打印 Helm client 版本信息</td>
</tr>
</tbody></table>
<p><strong>常用的 Helm 命令</strong></p>
<p>列出当前所有 repo</p>
<p><code>helm repo list</code></p>
<p>添加名为 internal 的 repo ，仓库地址为internal&#x2F;Charts</p>
<p><code>helm add internal internal/Charts</code></p>
<p>在 repo 中搜索名称为 mysql 的 Chart 包</p>
<p><code>helm search repo mysql</code></p>
<p>下载 Chart 包到本地</p>
<p><code>helm pull stable/mysql</code></p>
<p>安装 Chart 包到集群，将 release 命名为 instance01</p>
<p><code>helm install stable/mysql --name instance01</code></p>
<p>查询 myapp 这个 release 的状态<br><code>helm status myapp</code></p>
<p>列出 myapp 的历史 release 版本</p>
<p><code>helm history myapp</code></p>
<p>将 myapp 这个 release 的版本回退到版本 2</p>
<p><code>helm rollback myapp 2</code></p>
<p>将 myapp 这个 release 升级到版本 4</p>
<p><code>helm upgrade myapp --version 4</code></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://guoltan.github.io/2020/11/16/Node%20NotReady%20%E6%8E%92%E6%9F%A5%E6%8C%87%E5%BC%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="guoltan">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="guoltan个人博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | guoltan个人博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/11/16/Node%20NotReady%20%E6%8E%92%E6%9F%A5%E6%8C%87%E5%BC%95/" class="post-title-link" itemprop="url">Node NotReady 排查指引</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2020-11-16 18:11:25" itemprop="dateCreated datePublished" datetime="2020-11-16T18:11:25+08:00">2020-11-16</time>
    </span>

  
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>15k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>27 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Kubernetes-Node-NotReady-排查指引"><a href="#Kubernetes-Node-NotReady-排查指引" class="headerlink" title="Kubernetes Node NotReady 排查指引"></a>Kubernetes Node NotReady 排查指引</h1><h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><h3 id="Node"><a href="#Node" class="headerlink" title="Node"></a>Node</h3><p>  Kubernetes 对节点的定义是，接受来自控制平面的管理，运行 Pod （业务容器组）来执行工作负载，完成工作。节点可以是虚拟机或者物理机。Kubernetes 的集群由若干个节点组成。</p>
<p>  节点又分为 Master 和 Worker，Master 节点上运行着管控组件，如控制器，调度器等等。 Worker 节点则运行着集群的业务应用。</p>
<p>  Node 上的核心组件为 kubelet、container runtime、kube-proxy。</p>
<h3 id="Kubelet"><a href="#Kubelet" class="headerlink" title="Kubelet"></a>Kubelet</h3><p>  负责维护 Pod 的生命周期（创建&#x2F;启动&#x2F;监控&#x2F;重启&#x2F;销毁等），Kubelet 用于来确保各个 Pod 在 Node 上运行的状态符合预期。Master 通过 Kubelet 来发布指示，从而管理各个 Worker。</p>
<p>  Kubelet 不管理非 Kubernetes 集群创建的容器。</p>
<h3 id="container-runtime"><a href="#container-runtime" class="headerlink" title="container runtime"></a>container runtime</h3><p>  实际上提供运行容器能力的软件，kubelet 通过调用 container runtime 来完成容器的生命周期管理工作。常见的 container runtime 有 containerd，cri-o，docker等等。</p>
<h2 id="节点NotReady-的排查思路"><a href="#节点NotReady-的排查思路" class="headerlink" title="节点NotReady 的排查思路"></a>节点NotReady 的排查思路</h2><h3 id="如何诊断-K8S-集群是否出现节点-NotReady-或者驱逐的情况"><a href="#如何诊断-K8S-集群是否出现节点-NotReady-或者驱逐的情况" class="headerlink" title="如何诊断 K8S 集群是否出现节点 NotReady 或者驱逐的情况"></a>如何诊断 K8S 集群是否出现节点 NotReady 或者驱逐的情况</h3><p>  可以从两方面入手，一个是观察当前集群的 Pod 状态，另一个是节点状态。</p>
<p>  当某节点状态切换为 NotReady 以后，该状态维持超过 5 分钟时，会对该节点的 Pod 进行驱逐动作。除了节点 NotReady之外，如果节点因为磁盘空间、内存不足等原因也会导致出现 Pod 驱逐的情况。此时可以看到 Evicted状态的 Pod。</p>
<h3 id="收集节点-NotReady-的原因"><a href="#收集节点-NotReady-的原因" class="headerlink" title="收集节点 NotReady 的原因"></a>收集节点 NotReady 的原因</h3><h4 id="1-通过-kubectl-describe-node-获取-Node-的状态"><a href="#1-通过-kubectl-describe-node-获取-Node-的状态" class="headerlink" title="1. 通过 kubectl describe node 获取 Node 的状态"></a>1. 通过 kubectl describe node 获取 Node 的状态</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@tke-192-168-0-7 pki]# kubectl describe node 192.168.0.13 | grep -i -A10 Conditions</span><br><span class="line">Conditions:</span><br><span class="line">  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message</span><br><span class="line">  ----             ------  -----------------                 ------------------                ------                       -------</span><br><span class="line">  MemoryPressure   False   Wed, 21 Apr 2021 14:50:38 +0800   Tue, 16 Mar 2021 14:14:33 +0800   KubeletHasSufficientMemory   kubelet has sufficient memory available</span><br><span class="line">  DiskPressure     False   Wed, 21 Apr 2021 14:50:38 +0800   Sun, 04 Apr 2021 21:48:01 +0800   KubeletHasNoDiskPressure     kubelet has no disk pressure</span><br><span class="line">  PIDPressure      False   Wed, 21 Apr 2021 14:50:38 +0800   Tue, 16 Mar 2021 14:14:33 +0800   KubeletHasSufficientPID      kubelet has sufficient PID available</span><br><span class="line">  Ready            True    Wed, 21 Apr 2021 14:50:38 +0800   Wed, 17 Mar 2021 14:15:14 +0800   KubeletReady                 kubelet is posting ready status</span><br></pre></td></tr></table></figure>

<p>  通过 describe 查询 Conditions 字段能够比较快速的获取到 NotReady 的原因，在 Ready 这一行通常会告诉我们状态为 False 的原因是什么。对节点 NotReady 问题处理时，可以先通过该方法迅速获取 NotReady 的起因。</p>
<p>  对于出现复杂 NotReady 的场景，光通过 describe node 的方法可能并不能完全确认原因。此时我们还会借助其他手段获取信息。通用的排查方法即是查询 kubelet 相关的日志信息。</p>
<h4 id="2-查询-kubelet-日志"><a href="#2-查询-kubelet-日志" class="headerlink" title="2. 查询 kubelet 日志"></a>2. 查询 kubelet 日志</h4><p>  通过  journalctl -u kubelet 可以获取最新的 kubelet 的日志。查询 kubelet 日志能够得到更加细致的错误信息。便于我们定位问题。下面是一些常用的 journalctl 获取日志的方法。</p>
<h5 id="获取最新的-kubelet-日志"><a href="#获取最新的-kubelet-日志" class="headerlink" title="获取最新的 kubelet 日志"></a>获取最新的 kubelet 日志</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">-r 参数相当于倒排，优先显示最新的日志信息。</span></span><br><span class="line">journalctl -u kubelet -r</span><br></pre></td></tr></table></figure>

<h5 id="获取最近一个小时的-kubelet-日志"><a href="#获取最近一个小时的-kubelet-日志" class="headerlink" title="获取最近一个小时的 kubelet 日志"></a>获取最近一个小时的 kubelet 日志</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">journalctl -u kubelet --since &quot;1 hour ago&quot;</span><br></pre></td></tr></table></figure>

<h5 id="获取最近某个时间段的的-kubelet-日志"><a href="#获取最近某个时间段的的-kubelet-日志" class="headerlink" title="获取最近某个时间段的的 kubelet 日志"></a>获取最近某个时间段的的 kubelet 日志</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">获取 2021-04-28 的 20:00 到 20:15 之间的 kubelet 日志。</span></span><br><span class="line">journalctl -u kubelet --since &quot;2021-04-28 20:00:00&quot; --until &quot;2021-04-28 20:15:00&quot;</span><br></pre></td></tr></table></figure>

<h4 id="3-查询-message-日志"><a href="#3-查询-message-日志" class="headerlink" title="3. 查询 message 日志"></a>3. 查询 message 日志</h4><p>  kubelet 的输出也打到了 &#x2F;var&#x2F;log&#x2F;messages，我们同样也可以通过分析 message 中的相关错误信息来分析问题。对于曾出现过 NotReady 并且重启过的节点，此时通过可以通过 messages 日志来进行分析。</p>
<p>  如果涉及到需要将 message 日志拷贝给后端大佬分析的场景，要注意一下 message 文件的大小。在没有做分片转储的场景下，message 日志往往会很大。可以通过如下指令压缩 message 文件再提取出环境，减少传输成本。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">打包压缩 messages 文件</span></span><br><span class="line">tar zcvf messages-$(date +&quot;%Y%m%d-%H%M%S&quot;).tar.gz messages*</span><br></pre></td></tr></table></figure>

<h2 id="常见案例"><a href="#常见案例" class="headerlink" title="常见案例"></a>常见案例</h2><h3 id="节点资源不足"><a href="#节点资源不足" class="headerlink" title="节点资源不足"></a>节点资源不足</h3><h4 id="故障现象"><a href="#故障现象" class="headerlink" title="故障现象"></a>故障现象</h4><p>  通过 <code>kubectl describe node x.x.x.x | grep -A10 Conditions</code> 查询到类似的信息。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Conditions:</span><br><span class="line">  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message</span><br><span class="line">  ----                 ------  -----------------                 ------------------                ------                       -------</span><br><span class="line">  NetworkUnavailable   False   Tue, 27 Apr 2021 12:28:53 +0800   Tue, 27 Apr 2021 12:28:53 +0800   FlannelIsUp                  Flannel is running on this node</span><br><span class="line">  MemoryPressure       False   Wed, 28 Apr 2021 23:06:47 +0800   Fri, 23 Apr 2021 01:20:55 +0800   KubeletHasSufficientMemory   kubelet has sufficient memory available</span><br><span class="line">  DiskPressure         True    Wed, 28 Apr 2021 23:06:47 +0800   Wed, 28 Apr 2021 22:41:27 +0800   KubeletHasDiskPressure       kubelet has disk pressure</span><br><span class="line">  PIDPressure          False   Wed, 28 Apr 2021 23:06:47 +0800   Fri, 23 Apr 2021 01:20:55 +0800   KubeletHasSufficientPID      kubelet has sufficient PID available</span><br><span class="line">  Ready                True    Wed, 28 Apr 2021 23:06:47 +0800   Fri, 23 Apr 2021 01:25:30 +0800   KubeletReady                 kubelet is posting ready status</span><br></pre></td></tr></table></figure>

<p>  Type 字段中，如果 DiskPress 的 Status 为 True 时，则代表节点的磁盘空间不足。默认情况下 kubelet </p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Events:</span><br><span class="line">  Type     Reason                Age                    From     Message</span><br><span class="line">  ----     ------                ----                   ----     -------</span><br><span class="line">  Normal   NodeHasDiskPressure   53m                    kubelet  Node k8s-master01 status is now: NodeHasDiskPressure</span><br><span class="line">  Warning  FreeDiskSpaceFailed   53m                    kubelet  failed to garbage collect required amount of images. Wanted to free 2108570828 bytes, but freed 0 bytes</span><br><span class="line">  Warning  EvictionThresholdMet  3m53s (x296 over 53m)  kubelet  Attempting to reclaim ephemeral-storage</span><br></pre></td></tr></table></figure>

<h4 id="触发原因"><a href="#触发原因" class="headerlink" title="触发原因"></a>触发原因</h4><p>  通常是节点的某一项指标（如内存、磁盘空间、PID等等）的使用率超出阈值引起的。可以根据 <code>MemoryPressure</code>、<code>DiskPressure</code> 、<code>PIDPressure</code> 的状态是否为 True 来进一步排查原因。</p>
<p>  各指标的阈值默认如下</p>
<ul>
<li>memory.available&lt;100Mi</li>
<li>nodefs.available&lt;10%</li>
<li>nodefs.inodesFree&lt;5％</li>
<li>imagefs.available&lt;15%</li>
</ul>
<h4 id="排查方法"><a href="#排查方法" class="headerlink" title="排查方法"></a>排查方法</h4><p>  如果是 DiskPressure 状态为 true 的场景，通常可能是根文件系统、镜像文件系统资源不足引起的，请检查各个磁盘当前空间、i节点的使用率。通常可以用如下方法获取信息</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">获取块设备挂载情况</span></span><br><span class="line">[192.168.122.101 ~ ]# lsblk</span><br><span class="line">NAME            MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT</span><br><span class="line">sr0              11:0    1 1024M  0 rom</span><br><span class="line">vda             252:0    0   20G  0 disk</span><br><span class="line">├─vda2          252:2    0   19G  0 part</span><br><span class="line">│ ├─centos-swap 253:1    0    2G  0 lvm</span><br><span class="line">│ └─centos-root 253:0    0   17G  0 lvm  /</span><br><span class="line">└─vda1          252:1    0    1G  0 part /boot</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">获取目录挂载磁盘空间使用情况</span></span><br><span class="line">[192.168.122.101 ~ ]# df -lh /</span><br><span class="line">Filesystem               Size  Used Avail Use% Mounted on</span><br><span class="line">/dev/mapper/centos-root   17G  3.2G   14G  19% /</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">获取目录挂载磁盘i节点使用情况</span></span><br><span class="line">[192.168.122.101 ~ ]# df -iH /</span><br><span class="line">Filesystem              Inodes IUsed IFree IUse% Mounted on</span><br><span class="line">/dev/mapper/centos-root   3.2M   42k  3.1M    2% /</span><br></pre></td></tr></table></figure>

<p>  如果是 MemoryPressure 状态为 true 的场景，通常是节点的内存可用量不足导致的，可以通过如下方法获取信息</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">获取节点内存使用率</span></span><br><span class="line">free -g</span><br></pre></td></tr></table></figure>

<p>  如果是 PidPressure 状态为 true 的场景，可能是当前节点的 PID 数量很接近 &#x2F;proc&#x2F;sys&#x2F;kernel&#x2F;pid_max 中给出的值，可以根据如下方法获取信息确认。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">获取当前节点 pid 最大值</span></span><br><span class="line">cat /proc/sys/kernel/pid_max</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">获取当前节点 PID 数量</span></span><br><span class="line">ps -ef | wc -l </span><br></pre></td></tr></table></figure>

<blockquote>
<p>节点资源不足，不会将节点配置为 NotReady，但节点上的 Pod 会驱逐，该类问题也需要重点关注。</p>
</blockquote>
<h3 id="Kubelet（golang）BUG"><a href="#Kubelet（golang）BUG" class="headerlink" title="Kubelet（golang）BUG"></a>Kubelet（golang）BUG</h3><h4 id="故障现象-1"><a href="#故障现象-1" class="headerlink" title="故障现象"></a>故障现象</h4><p>   节点状态变为 NotReady</p>
<p>   通过 <code>kubectl describe node x.x.x.x | grep -A10 Conditions</code> 查询，LastHeartbeatTime、LastTransitionTime的状态近期再没有更新过数据。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Conditions:</span><br><span class="line">  Type                 Status    LastHeartbeatTime                 LastTransitionTime                Reason              Message</span><br><span class="line">  ----                 ------    -----------------                 ------------------                ------              -------</span><br><span class="line">  NetworkUnavailable   False     Thu, 06 May 2021 10:24:38 +0800   Thu, 06 May 2021 10:24:38 +0800   FlannelIsUp         Flannel is running on this node</span><br><span class="line">  MemoryPressure       Unknown   Thu, 06 May 2021 13:40:00 +0800   Thu, 06 May 2021 13:41:35 +0800   NodeStatusUnknown   Kubelet stopped posting node status.</span><br><span class="line">  DiskPressure         Unknown   Thu, 06 May 2021 13:40:00 +0800   Thu, 06 May 2021 13:41:35 +0800   NodeStatusUnknown   Kubelet stopped posting node status.</span><br><span class="line">  PIDPressure          Unknown   Thu, 06 May 2021 13:40:00 +0800   Thu, 06 May 2021 13:41:35 +0800   NodeStatusUnknown   Kubelet stopped posting node status.</span><br><span class="line">  Ready                Unknown   Thu, 06 May 2021 13:40:00 +0800   Thu, 06 May 2021 13:41:35 +0800   NodeStatusUnknown   Kubelet stopped posting node status.</span><br></pre></td></tr></table></figure>

<h4 id="触发原因-1"><a href="#触发原因-1" class="headerlink" title="触发原因"></a>触发原因</h4><p>​    该问题是社区的一个 BUG，节点概率性会触发，一旦触发该 BUG 会导致节点无法更新状态。最终导致节点被置为 NotReady。</p>
<h4 id="排查方法-1"><a href="#排查方法-1" class="headerlink" title="排查方法"></a>排查方法</h4><p>  方法一：通过 journalctl 查询 kubelet 日志的是否存在关键字</p>
<p>  方法二：通过查看 messages 日志，过滤相关关键字判断</p>
<p>​    <code>grep -i &quot;use of closed network connection&quot; /var/log/messages</code></p>
<p>  该问题目前在社区的 kubernetes 1.18 版本得到了解决，TKE 3.4.X 版本默认修复了这个问题。在 TKE 3.0.4 通过配置检测脚本来自动重启 kubelet 修复。对于 TKE 3.0.4 之前的版本，可以参考如下链接进行临时规避修复：</p>
<p><a target="_blank" rel="noopener" href="https://gdc.lexiangla.com/teams/k100044/docs/c2b199b4780f11ebaee046cd73dfa810?company_from=gdc">https://gdc.lexiangla.com/teams/k100044/docs/c2b199b4780f11ebaee046cd73dfa810?company_from=gdc</a></p>
<h3 id="PLEG-检测失败"><a href="#PLEG-检测失败" class="headerlink" title="PLEG 检测失败"></a>PLEG 检测失败</h3><h4 id="故障现象-2"><a href="#故障现象-2" class="headerlink" title="故障现象"></a>故障现象</h4><p>  如果节点出现了 PLEG 超时的问题，可以观察到这个节点它的 Ready、NotReady 状态的切换会很频繁，处于一个不稳定的状态。</p>
<p>  通过 <code>kubectl describe node x.x.x.x | grep -A10 Conditions</code> 查询到类似的信息。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Conditions:</span><br><span class="line">  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message</span><br><span class="line">  ----                 ------  -----------------                 ------------------                ------                       -------</span><br><span class="line">  NetworkUnavailable   False   Tue, 27 Apr 2021 12:28:53 +0800   Tue, 27 Apr 2021 12:28:53 +0800   FlannelIsUp                  Flannel is running on this node</span><br><span class="line">  MemoryPressure       False   Wed, 28 Apr 2021 23:06:47 +0800   Fri, 23 Apr 2021 01:20:55 +0800   KubeletHasSufficientMemory   kubelet has sufficient memory available</span><br><span class="line">  DiskPressure         True    Wed, 28 Apr 2021 23:06:47 +0800   Wed, 28 Apr 2021 22:41:27 +0800   KubeletHasDiskPressure       kubelet has disk pressure</span><br><span class="line">  PIDPressure          False   Wed, 28 Apr 2021 23:06:47 +0800   Fri, 23 Apr 2021 01:20:55 +0800   KubeletHasSufficientPID      kubelet has sufficient PID available</span><br><span class="line">  Ready                False   Wed, 28 Apr 2021 23:06:47 +0800   Sun, 06 Dec 2020 18:49:40 +0100   KubeletNotReady              PLEG is not healthy: pleg was last seen active 10m18.040734348s ago; threshold is 3m0s</span><br></pre></td></tr></table></figure>

<h4 id="触发原因-2"><a href="#触发原因-2" class="headerlink" title="触发原因"></a>触发原因</h4><p>  PLEG 是 Pod Lifecycle Event Generator（Pod 生命周期事件生成器），它用来周期性收集节点上各个 Pod 的状态，并将 Pod 状态写入到缓存中。让控制器能够根据最新 Pod 的状态进行控制。</p>
<p>  在周期性的 relist（收集容器状态信息）的操作中，如果超出了默认预定的事件阈值（默认 3 分钟），就会触发事件，将 Node 状态切换为 NotReady。</p>
<p>  我们可以简单的理解 relist 的动作就是 docker ps 列出所有容器，再进一步 inspect 这些容器的信息。</p>
<p>  可能导致 relist 超出 3 分钟的原因如下：</p>
<ul>
<li>节点上运行了大量的 Pod，导致 relist 收集超时。</li>
<li>节点的负载较高，性能不足，导致 relist 收集超时。</li>
<li>有部分容器处于 Dead 或者其他状态（如，长时间Create），阻塞 inspect。</li>
</ul>
<h4 id="排查方法-2"><a href="#排查方法-2" class="headerlink" title="排查方法"></a>排查方法</h4><p>  <strong>原因1 节点上运行了大量的 Pod，导致 relist 收集超时。</strong></p>
<p>​    确认该节点的 Pod 运行数量，以及容器数量</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">获取 Pod 数量</span></span><br><span class="line">kubectl get pod -o wide -A | grep -i 节点IP（名称） | wc -l</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">获取 Pod 数量，更简洁的方法</span></span><br><span class="line">kubectl describe node 节点名称 | grep -i Non-terminated</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">获取容器数量</span></span><br><span class="line">docker ps -a | wc -l</span><br></pre></td></tr></table></figure>

<p>  <strong>原因2 节点负载较高，性能不足，导致 relist 收集超时。</strong></p>
<p>​    可以通过判断该节点的负载来确认，通过 top 等指令确认 CPU、内存、IO等负载情况。可以关注一下 wa 的值。如果 wa 值比较大，再通过 iostat 进一步获取 IO 数据。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">top</span></span><br><span class="line">[192.168.7.221 ~ ]# top</span><br><span class="line">top - 14:15:51 up  3:55,  1 user,  load average: 1.41, 0.99, 0.91</span><br><span class="line">Tasks: 348 total,   1 running, 347 sleeping,   0 stopped,   0 zombie</span><br><span class="line"><span class="meta prompt_">%</span><span class="language-bash">Cpu(s):  2.6 us,  1.2 sy,  0.0 ni, 96.2 <span class="built_in">id</span>,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span></span><br><span class="line">KiB Mem : 74012144 total, 35444780 free, 17865776 used, 20701592 buff/cache</span><br><span class="line">KiB Swap: 10485760+total, 10485760+free,        0 used. 55667436 avail Mem</span><br><span class="line"></span><br><span class="line">  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND</span><br><span class="line"> 1880 root      20   0 5479028   2.2g  11216 S  31.2  3.1  86:37.15 qemu-kvm</span><br><span class="line"> 1904 root      20   0 5360192   2.2g  11236 S  18.8  3.2  75:41.94 qemu-kvm</span><br><span class="line">16146 root      20   0 5040564   2.3g  11212 S  18.8  3.3   5:59.33 qemu-kvm</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">iostat</span></span><br><span class="line">[192.168.7.221 ~ ]# iostat -x</span><br><span class="line">Linux 3.10.0-1160.24.1.el7.x86_64 (localhost.localdomain)       05/06/2021      _x86_64_        (24 CPU)</span><br><span class="line"></span><br><span class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</span><br><span class="line">           3.65    0.00    1.37    0.16    0.00   94.82</span><br><span class="line"></span><br><span class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</span><br><span class="line">sda               0.00     0.07    0.39    0.45    14.76     3.83    44.06     0.00    4.66    9.51    0.39   0.85   0.07</span><br><span class="line">sdb               0.00     0.01    6.49  107.14   442.68  1295.89    30.60     0.30    2.68   12.67    2.08   0.12   1.41</span><br><span class="line">dm-0              0.00     0.00    6.49  107.15   442.64  1296.16    30.60     0.31    2.69   12.68    2.09   0.13   1.43</span><br></pre></td></tr></table></figure>

<p>  <strong>原因3 有部分容器处于 Dead 或者其他状态（如，长时间Create）阻塞 inspect。</strong></p>
<p>​    可以通过复现 relist 的行为，来判断卡点，我们可以从 docker ps + docker inspect 执行的来判断是否有阻塞的容器，进一步获取信息。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">到触发了 PLEG 超时的节点上执行如下操作</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">收集是否有卡死的容器</span></span><br><span class="line">for c in $(docker ps -aq); do echo $c; docker inspect $c 1&gt;/dev/null 2&gt;&amp;1; done</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">进一步查看卡死容器的状态，此处 cid 是上一条命令执行获取到的数据。</span></span><br><span class="line">docker ps -a | grep $cid</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">如果状态是 Dead，通过 docker <span class="built_in">rm</span> -f <span class="variable">$cid</span> 来进行处理</span></span><br><span class="line">docker rm -f $cid</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">如果状态是 Create，收集 stack 信息，提供给后端同学进一步分析问题</span></span><br><span class="line">cat /proc/PID/stack</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">另外可以收集一下 dmesg 是否存在相关的内核错误信息。</span></span><br><span class="line">dmesg -T</span><br></pre></td></tr></table></figure>

<p>​    如果在 dmesg 等看到了 XFS 分配内存失败的相关错误信息，还请收集如下信息</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">获取内核版本，注意低于 3.10.1062 的内核版本存在 XFS 碎片的 BUG。</span></span><br><span class="line">uname -r </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查询内存碎片</span></span><br><span class="line">cat /proc/buddyinfo</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">获取 XFS 版本</span></span><br><span class="line">xfs_info</span><br></pre></td></tr></table></figure>

<h3 id="Container-Runtime-故障"><a href="#Container-Runtime-故障" class="headerlink" title="Container Runtime 故障"></a>Container Runtime 故障</h3><h4 id="故障现象-3"><a href="#故障现象-3" class="headerlink" title="故障现象"></a>故障现象</h4><p>  通过 <code>kubectl describe node x.x.x.x | grep -A10 Conditions</code> 查询到类似的信息。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Conditions:</span><br><span class="line">  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message</span><br><span class="line">  ----                 ------  -----------------                 ------------------                ------                       -------</span><br><span class="line">  NetworkUnavailable   False   Thu, 06 May 2021 10:23:35 +0800   Thu, 06 May 2021 10:23:35 +0800   FlannelIsUp                  Flannel is running on this node</span><br><span class="line">  MemoryPressure       False   Thu, 06 May 2021 13:29:26 +0800   Thu, 06 May 2021 09:57:18 +0800   KubeletHasSufficientMemory   kubelet has sufficient memory available</span><br><span class="line">  DiskPressure         False   Thu, 06 May 2021 13:29:26 +0800   Thu, 06 May 2021 09:57:18 +0800   KubeletHasNoDiskPressure     kubelet has no disk pressure</span><br><span class="line">  PIDPressure          False   Thu, 06 May 2021 13:29:26 +0800   Thu, 06 May 2021 09:57:18 +0800   KubeletHasSufficientPID      kubelet has sufficient PID available</span><br><span class="line">  Ready                False   Thu, 06 May 2021 13:29:26 +0800   Thu, 06 May 2021 13:28:55 +0800   KubeletNotReady              [container runtime is down, container runtime not ready: RuntimeReady=false reason:DockerDaemonNotReady message:docker: failed to get docker version: Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?]</span><br></pre></td></tr></table></figure>

<h4 id="触发原因-3"><a href="#触发原因-3" class="headerlink" title="触发原因"></a>触发原因</h4><p>  通过 Conditions 中的 KubeletNotReady Reason 可以得知，这是因为连接 docker 失败导致的。</p>
<h4 id="排查方法-3"><a href="#排查方法-3" class="headerlink" title="排查方法"></a>排查方法</h4><p>​    获取 docker 状态是否为 Running，如果不是 Running，收集 docker 的日志来进一步排查，同时也可以尝试手动拉起修复 docker。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查询 docker 运行状态</span></span><br><span class="line">systemctl status docker</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">收集 docker 日志</span></span><br><span class="line">journalctl -u docker &gt; docker-$(date +&quot;%Y%m%d-%H%M%S&quot;).log</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">手动启动 docker</span></span><br><span class="line">systemctl start docker</span><br></pre></td></tr></table></figure>

<h3 id="节点网络不通"><a href="#节点网络不通" class="headerlink" title="节点网络不通"></a>节点网络不通</h3><h4 id="故障现象-4"><a href="#故障现象-4" class="headerlink" title="故障现象"></a>故障现象</h4><p>   通过 <code>kubectl describe node x.x.x.x | grep -A10 Conditions</code> 查询，LastHeartbeatTime、LastTransitionTime的状态近期再没有更新过数据。</p>
<p>   因为节点与控制器之间的网络不通，状态无法上报给控制器，这个时候 describe 出的结果和 kubelet(golang) BUG 触发的现象类似。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Conditions:</span><br><span class="line">  Type                 Status    LastHeartbeatTime                 LastTransitionTime                Reason              Message</span><br><span class="line">  ----                 ------    -----------------                 ------------------                ------              -------</span><br><span class="line">  NetworkUnavailable   False     Thu, 06 May 2021 10:24:38 +0800   Thu, 06 May 2021 10:24:38 +0800   FlannelIsUp         Flannel is running on this node</span><br><span class="line">  MemoryPressure       Unknown   Thu, 06 May 2021 13:40:00 +0800   Thu, 06 May 2021 13:41:35 +0800   NodeStatusUnknown   Kubelet stopped posting node status.</span><br><span class="line">  DiskPressure         Unknown   Thu, 06 May 2021 13:40:00 +0800   Thu, 06 May 2021 13:41:35 +0800   NodeStatusUnknown   Kubelet stopped posting node status.</span><br><span class="line">  PIDPressure          Unknown   Thu, 06 May 2021 13:40:00 +0800   Thu, 06 May 2021 13:41:35 +0800   NodeStatusUnknown   Kubelet stopped posting node status.</span><br><span class="line">  Ready                Unknown   Thu, 06 May 2021 13:40:00 +0800   Thu, 06 May 2021 13:41:35 +0800   NodeStatusUnknown   Kubelet stopped posting node status.</span><br></pre></td></tr></table></figure>

<h4 id="触发原因-4"><a href="#触发原因-4" class="headerlink" title="触发原因"></a>触发原因</h4><p>  可能是节点下线或者因为其他原因导致网络阻塞，节点无法与控制器正常通信。</p>
<h4 id="排查方法-4"><a href="#排查方法-4" class="headerlink" title="排查方法"></a>排查方法</h4><p>  确认目标节点是否存活，如果存活的话，进一步测试该节点与其他节点之间的连通性。是否有可能是防火墙或者其他因素阻塞了连通性。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">确认目标节点是否存活</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在其他节点执行如下操作</span></span><br><span class="line">ping 目标节点IP</span><br><span class="line">ssh 目标节点IP</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">如果目标节点存活，进一步排查它与其他节点之间的连通性。</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">登录到目标节点执行如下操作</span></span><br><span class="line">ping 其他节点地址</span><br><span class="line">curl apiserver:6443</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://guoltan.github.io/2020/09/25/chrony%E4%B8%BB%E6%9C%BA%E6%97%B6%E9%92%9F%E5%90%8C%E6%AD%A5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="guoltan">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="guoltan个人博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | guoltan个人博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/09/25/chrony%E4%B8%BB%E6%9C%BA%E6%97%B6%E9%92%9F%E5%90%8C%E6%AD%A5/" class="post-title-link" itemprop="url">chrony主机时钟同步</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2020-09-25 18:00:25" itemprop="dateCreated datePublished" datetime="2020-09-25T18:00:25+08:00">2020-09-25</time>
    </span>

  
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>3.3k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>6 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <ol>
<li>安装 chrony</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y install chrony</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>配置 chrony</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/chrony.conf</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">找到 server 区块，全注释，替换为 aliyun 时钟源</span></span><br><span class="line"></span><br><span class="line">server ntp1.aliyun.com iburst</span><br><span class="line">server ntp2.aliyun.com iburst</span><br><span class="line">server ntp3.aliyun.com iburst</span><br><span class="line">server ntp4.aliyun.com iburst</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>启动 chrony 并设置开机自启动</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl enable chronyd</span><br><span class="line">systemctl start chronyd</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>修改时区、查看时区</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">设置时区为上海</span></span><br><span class="line">timedatectl set-timezone Asia/Shanghai</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看当前时区和时钟同步情况</span></span><br><span class="line">timedatectl status</span><br></pre></td></tr></table></figure>

<ol start="5">
<li>配置硬件时钟和系统时钟一致</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">如果是配置系统时钟和硬件时钟保持一致，则可以使用 -s 参数</span></span><br><span class="line">hwclock -w</span><br></pre></td></tr></table></figure>

<ol start="6">
<li>chronyc 运维指令</li>
</ol>
<p><strong>查看当前机器同步的 ntp 服务器</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chronyc sources -v</span><br></pre></td></tr></table></figure>

<p>  示例输出：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@cloud-master01 kube-prometheus]# chronyc sources -v</span><br><span class="line">210 Number of sources = 1</span><br><span class="line"></span><br><span class="line">  .-- Source mode  &#x27;^&#x27; = server, &#x27;=&#x27; = peer, &#x27;#&#x27; = local clock.</span><br><span class="line"> / .- Source state &#x27;*&#x27; = current synced, &#x27;+&#x27; = combined , &#x27;-&#x27; = not combined,</span><br><span class="line">| /   &#x27;?&#x27; = unreachable, &#x27;x&#x27; = time may be in error, &#x27;~&#x27; = time too variable.</span><br><span class="line">||                                                 .- xxxx [ yyyy ] +/- zzzz</span><br><span class="line">||      Reachability register (octal) -.           |  xxxx = adjusted offset,</span><br><span class="line">||      Log2(Polling interval) --.      |          |  yyyy = measured offset,</span><br><span class="line">||                                \     |          |  zzzz = estimated error.</span><br><span class="line">||                                 |    |           \</span><br><span class="line">MS Name/IP address         Stratum Poll Reach LastRx Last sample</span><br><span class="line">===============================================================================</span><br><span class="line">^* 120.25.115.20                 2   6   337    64   -550us[ -759us] +/- 9876us</span><br></pre></td></tr></table></figure>

<p><strong>查看 ntp 服务器状态</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chronyc sourcestats -v</span><br></pre></td></tr></table></figure>

<p>  示例输出</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">210 Number of sources = 1</span><br><span class="line">                             .- Number of sample points in measurement set.</span><br><span class="line">                            /    .- Number of residual runs with same sign.</span><br><span class="line">                           |    /    .- Length of measurement set (time).</span><br><span class="line">                           |   |    /      .- Est. clock freq error (ppm).</span><br><span class="line">                           |   |   |      /           .- Est. error in freq.</span><br><span class="line">                           |   |   |     |           /         .- Est. offset.</span><br><span class="line">                           |   |   |     |          |          |   On the -.</span><br><span class="line">                           |   |   |     |          |          |   samples. \</span><br><span class="line">                           |   |   |     |          |          |             |</span><br><span class="line">Name/IP Address            NP  NR  Span  Frequency  Freq Skew  Offset  Std Dev</span><br><span class="line">==============================================================================</span><br><span class="line">120.25.115.20              11   9   525     -0.053      8.843  -6245ns  1074us</span><br></pre></td></tr></table></figure>

<p><strong>查看 ntp 服务器是否在线</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chronyc activity -v</span><br></pre></td></tr></table></figure>

<p>  示例输出：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@cloud-master01 kube-prometheus]# chronyc activity -v</span><br><span class="line">200 OK</span><br><span class="line">1 sources online</span><br><span class="line">0 sources offline</span><br><span class="line">0 sources doing burst (return to online)</span><br><span class="line">0 sources doing burst (return to offline)</span><br><span class="line">0 sources with unknown address</span><br></pre></td></tr></table></figure>

<p><strong>查看 ntp 服务器详细信息</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chronyc tracking -v</span><br></pre></td></tr></table></figure>

<p>  示例输出：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@cloud-master01 kube-prometheus]# chronyc tracking -v</span><br><span class="line">Reference ID    : 78197314 (120.25.115.20)</span><br><span class="line">Stratum         : 3</span><br><span class="line">Ref time (UTC)  : Fri Oct 06 14:40:05 2023</span><br><span class="line">System time     : 0.000293604 seconds fast of NTP time</span><br><span class="line">Last offset     : +0.000001403 seconds</span><br><span class="line">RMS offset      : 0.000997817 seconds</span><br><span class="line">Frequency       : 6.722 ppm fast</span><br><span class="line">Residual freq   : +0.016 ppm</span><br><span class="line">Skew            : 4.444 ppm</span><br><span class="line">Root delay      : 0.013335334 seconds</span><br><span class="line">Root dispersion : 0.001928344 seconds</span><br><span class="line">Update interval : 65.3 seconds</span><br><span class="line">Leap status     : Normal</span><br></pre></td></tr></table></figure>

<p><strong>强制同步系统时钟</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chronyc -a makestep</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" title="上一页" aria-label="上一页" href="/page/2/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">guoltan</span>
  </div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>







  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>





</body>
</html>
