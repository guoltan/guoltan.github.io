<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Node NotReady 排查指引</title>
    <url>/2020/11/16/Node%20NotReady%20%E6%8E%92%E6%9F%A5%E6%8C%87%E5%BC%95/</url>
    <content><![CDATA[<h1 id="Kubernetes-Node-NotReady-排查指引"><a href="#Kubernetes-Node-NotReady-排查指引" class="headerlink" title="Kubernetes Node NotReady 排查指引"></a>Kubernetes Node NotReady 排查指引</h1><h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><h3 id="Node"><a href="#Node" class="headerlink" title="Node"></a>Node</h3><p>  Kubernetes 对节点的定义是，接受来自控制平面的管理，运行 Pod （业务容器组）来执行工作负载，完成工作。节点可以是虚拟机或者物理机。Kubernetes 的集群由若干个节点组成。</p>
<p>  节点又分为 Master 和 Worker，Master 节点上运行着管控组件，如控制器，调度器等等。 Worker 节点则运行着集群的业务应用。</p>
<p>  Node 上的核心组件为 kubelet、container runtime、kube-proxy。</p>
<h3 id="Kubelet"><a href="#Kubelet" class="headerlink" title="Kubelet"></a>Kubelet</h3><p>  负责维护 Pod 的生命周期（创建&#x2F;启动&#x2F;监控&#x2F;重启&#x2F;销毁等），Kubelet 用于来确保各个 Pod 在 Node 上运行的状态符合预期。Master 通过 Kubelet 来发布指示，从而管理各个 Worker。</p>
<p>  Kubelet 不管理非 Kubernetes 集群创建的容器。</p>
<h3 id="container-runtime"><a href="#container-runtime" class="headerlink" title="container runtime"></a>container runtime</h3><p>  实际上提供运行容器能力的软件，kubelet 通过调用 container runtime 来完成容器的生命周期管理工作。常见的 container runtime 有 containerd，cri-o，docker等等。</p>
<h2 id="节点NotReady-的排查思路"><a href="#节点NotReady-的排查思路" class="headerlink" title="节点NotReady 的排查思路"></a>节点NotReady 的排查思路</h2><h3 id="如何诊断-K8S-集群是否出现节点-NotReady-或者驱逐的情况"><a href="#如何诊断-K8S-集群是否出现节点-NotReady-或者驱逐的情况" class="headerlink" title="如何诊断 K8S 集群是否出现节点 NotReady 或者驱逐的情况"></a>如何诊断 K8S 集群是否出现节点 NotReady 或者驱逐的情况</h3><p>  可以从两方面入手，一个是观察当前集群的 Pod 状态，另一个是节点状态。</p>
<p>  当某节点状态切换为 NotReady 以后，该状态维持超过 5 分钟时，会对该节点的 Pod 进行驱逐动作。除了节点 NotReady之外，如果节点因为磁盘空间、内存不足等原因也会导致出现 Pod 驱逐的情况。此时可以看到 Evicted状态的 Pod。</p>
<h3 id="收集节点-NotReady-的原因"><a href="#收集节点-NotReady-的原因" class="headerlink" title="收集节点 NotReady 的原因"></a>收集节点 NotReady 的原因</h3><h4 id="1-通过-kubectl-describe-node-获取-Node-的状态"><a href="#1-通过-kubectl-describe-node-获取-Node-的状态" class="headerlink" title="1. 通过 kubectl describe node 获取 Node 的状态"></a>1. 通过 kubectl describe node 获取 Node 的状态</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@tke-192-168-0-7 pki]# kubectl describe node 192.168.0.13 | grep -i -A10 Conditions</span><br><span class="line">Conditions:</span><br><span class="line">  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message</span><br><span class="line">  ----             ------  -----------------                 ------------------                ------                       -------</span><br><span class="line">  MemoryPressure   False   Wed, 21 Apr 2021 14:50:38 +0800   Tue, 16 Mar 2021 14:14:33 +0800   KubeletHasSufficientMemory   kubelet has sufficient memory available</span><br><span class="line">  DiskPressure     False   Wed, 21 Apr 2021 14:50:38 +0800   Sun, 04 Apr 2021 21:48:01 +0800   KubeletHasNoDiskPressure     kubelet has no disk pressure</span><br><span class="line">  PIDPressure      False   Wed, 21 Apr 2021 14:50:38 +0800   Tue, 16 Mar 2021 14:14:33 +0800   KubeletHasSufficientPID      kubelet has sufficient PID available</span><br><span class="line">  Ready            True    Wed, 21 Apr 2021 14:50:38 +0800   Wed, 17 Mar 2021 14:15:14 +0800   KubeletReady                 kubelet is posting ready status</span><br></pre></td></tr></table></figure>

<p>  通过 describe 查询 Conditions 字段能够比较快速的获取到 NotReady 的原因，在 Ready 这一行通常会告诉我们状态为 False 的原因是什么。对节点 NotReady 问题处理时，可以先通过该方法迅速获取 NotReady 的起因。</p>
<p>  对于出现复杂 NotReady 的场景，光通过 describe node 的方法可能并不能完全确认原因。此时我们还会借助其他手段获取信息。通用的排查方法即是查询 kubelet 相关的日志信息。</p>
<h4 id="2-查询-kubelet-日志"><a href="#2-查询-kubelet-日志" class="headerlink" title="2. 查询 kubelet 日志"></a>2. 查询 kubelet 日志</h4><p>  通过  journalctl -u kubelet 可以获取最新的 kubelet 的日志。查询 kubelet 日志能够得到更加细致的错误信息。便于我们定位问题。下面是一些常用的 journalctl 获取日志的方法。</p>
<h5 id="获取最新的-kubelet-日志"><a href="#获取最新的-kubelet-日志" class="headerlink" title="获取最新的 kubelet 日志"></a>获取最新的 kubelet 日志</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">-r 参数相当于倒排，优先显示最新的日志信息。</span></span><br><span class="line">journalctl -u kubelet -r</span><br></pre></td></tr></table></figure>

<h5 id="获取最近一个小时的-kubelet-日志"><a href="#获取最近一个小时的-kubelet-日志" class="headerlink" title="获取最近一个小时的 kubelet 日志"></a>获取最近一个小时的 kubelet 日志</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">journalctl -u kubelet --since &quot;1 hour ago&quot;</span><br></pre></td></tr></table></figure>

<h5 id="获取最近某个时间段的的-kubelet-日志"><a href="#获取最近某个时间段的的-kubelet-日志" class="headerlink" title="获取最近某个时间段的的 kubelet 日志"></a>获取最近某个时间段的的 kubelet 日志</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">获取 2021-04-28 的 20:00 到 20:15 之间的 kubelet 日志。</span></span><br><span class="line">journalctl -u kubelet --since &quot;2021-04-28 20:00:00&quot; --until &quot;2021-04-28 20:15:00&quot;</span><br></pre></td></tr></table></figure>

<h4 id="3-查询-message-日志"><a href="#3-查询-message-日志" class="headerlink" title="3. 查询 message 日志"></a>3. 查询 message 日志</h4><p>  kubelet 的输出也打到了 &#x2F;var&#x2F;log&#x2F;messages，我们同样也可以通过分析 message 中的相关错误信息来分析问题。对于曾出现过 NotReady 并且重启过的节点，此时通过可以通过 messages 日志来进行分析。</p>
<p>  如果涉及到需要将 message 日志拷贝给后端大佬分析的场景，要注意一下 message 文件的大小。在没有做分片转储的场景下，message 日志往往会很大。可以通过如下指令压缩 message 文件再提取出环境，减少传输成本。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">打包压缩 messages 文件</span></span><br><span class="line">tar zcvf messages-$(date +&quot;%Y%m%d-%H%M%S&quot;).tar.gz messages*</span><br></pre></td></tr></table></figure>

<h2 id="常见案例"><a href="#常见案例" class="headerlink" title="常见案例"></a>常见案例</h2><h3 id="节点资源不足"><a href="#节点资源不足" class="headerlink" title="节点资源不足"></a>节点资源不足</h3><h4 id="故障现象"><a href="#故障现象" class="headerlink" title="故障现象"></a>故障现象</h4><p>  通过 <code>kubectl describe node x.x.x.x | grep -A10 Conditions</code> 查询到类似的信息。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Conditions:</span><br><span class="line">  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message</span><br><span class="line">  ----                 ------  -----------------                 ------------------                ------                       -------</span><br><span class="line">  NetworkUnavailable   False   Tue, 27 Apr 2021 12:28:53 +0800   Tue, 27 Apr 2021 12:28:53 +0800   FlannelIsUp                  Flannel is running on this node</span><br><span class="line">  MemoryPressure       False   Wed, 28 Apr 2021 23:06:47 +0800   Fri, 23 Apr 2021 01:20:55 +0800   KubeletHasSufficientMemory   kubelet has sufficient memory available</span><br><span class="line">  DiskPressure         True    Wed, 28 Apr 2021 23:06:47 +0800   Wed, 28 Apr 2021 22:41:27 +0800   KubeletHasDiskPressure       kubelet has disk pressure</span><br><span class="line">  PIDPressure          False   Wed, 28 Apr 2021 23:06:47 +0800   Fri, 23 Apr 2021 01:20:55 +0800   KubeletHasSufficientPID      kubelet has sufficient PID available</span><br><span class="line">  Ready                True    Wed, 28 Apr 2021 23:06:47 +0800   Fri, 23 Apr 2021 01:25:30 +0800   KubeletReady                 kubelet is posting ready status</span><br></pre></td></tr></table></figure>

<p>  Type 字段中，如果 DiskPress 的 Status 为 True 时，则代表节点的磁盘空间不足。默认情况下 kubelet </p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Events:</span><br><span class="line">  Type     Reason                Age                    From     Message</span><br><span class="line">  ----     ------                ----                   ----     -------</span><br><span class="line">  Normal   NodeHasDiskPressure   53m                    kubelet  Node k8s-master01 status is now: NodeHasDiskPressure</span><br><span class="line">  Warning  FreeDiskSpaceFailed   53m                    kubelet  failed to garbage collect required amount of images. Wanted to free 2108570828 bytes, but freed 0 bytes</span><br><span class="line">  Warning  EvictionThresholdMet  3m53s (x296 over 53m)  kubelet  Attempting to reclaim ephemeral-storage</span><br></pre></td></tr></table></figure>

<h4 id="触发原因"><a href="#触发原因" class="headerlink" title="触发原因"></a>触发原因</h4><p>  通常是节点的某一项指标（如内存、磁盘空间、PID等等）的使用率超出阈值引起的。可以根据 <code>MemoryPressure</code>、<code>DiskPressure</code> 、<code>PIDPressure</code> 的状态是否为 True 来进一步排查原因。</p>
<p>  各指标的阈值默认如下</p>
<ul>
<li>memory.available&lt;100Mi</li>
<li>nodefs.available&lt;10%</li>
<li>nodefs.inodesFree&lt;5％</li>
<li>imagefs.available&lt;15%</li>
</ul>
<h4 id="排查方法"><a href="#排查方法" class="headerlink" title="排查方法"></a>排查方法</h4><p>  如果是 DiskPressure 状态为 true 的场景，通常可能是根文件系统、镜像文件系统资源不足引起的，请检查各个磁盘当前空间、i节点的使用率。通常可以用如下方法获取信息</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">获取块设备挂载情况</span></span><br><span class="line">[192.168.122.101 ~ ]# lsblk</span><br><span class="line">NAME            MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT</span><br><span class="line">sr0              11:0    1 1024M  0 rom</span><br><span class="line">vda             252:0    0   20G  0 disk</span><br><span class="line">├─vda2          252:2    0   19G  0 part</span><br><span class="line">│ ├─centos-swap 253:1    0    2G  0 lvm</span><br><span class="line">│ └─centos-root 253:0    0   17G  0 lvm  /</span><br><span class="line">└─vda1          252:1    0    1G  0 part /boot</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">获取目录挂载磁盘空间使用情况</span></span><br><span class="line">[192.168.122.101 ~ ]# df -lh /</span><br><span class="line">Filesystem               Size  Used Avail Use% Mounted on</span><br><span class="line">/dev/mapper/centos-root   17G  3.2G   14G  19% /</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">获取目录挂载磁盘i节点使用情况</span></span><br><span class="line">[192.168.122.101 ~ ]# df -iH /</span><br><span class="line">Filesystem              Inodes IUsed IFree IUse% Mounted on</span><br><span class="line">/dev/mapper/centos-root   3.2M   42k  3.1M    2% /</span><br></pre></td></tr></table></figure>

<p>  如果是 MemoryPressure 状态为 true 的场景，通常是节点的内存可用量不足导致的，可以通过如下方法获取信息</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">获取节点内存使用率</span></span><br><span class="line">free -g</span><br></pre></td></tr></table></figure>

<p>  如果是 PidPressure 状态为 true 的场景，可能是当前节点的 PID 数量很接近 &#x2F;proc&#x2F;sys&#x2F;kernel&#x2F;pid_max 中给出的值，可以根据如下方法获取信息确认。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">获取当前节点 pid 最大值</span></span><br><span class="line">cat /proc/sys/kernel/pid_max</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">获取当前节点 PID 数量</span></span><br><span class="line">ps -ef | wc -l </span><br></pre></td></tr></table></figure>

<blockquote>
<p>节点资源不足，不会将节点配置为 NotReady，但节点上的 Pod 会驱逐，该类问题也需要重点关注。</p>
</blockquote>
<h3 id="Kubelet（golang）BUG"><a href="#Kubelet（golang）BUG" class="headerlink" title="Kubelet（golang）BUG"></a>Kubelet（golang）BUG</h3><h4 id="故障现象-1"><a href="#故障现象-1" class="headerlink" title="故障现象"></a>故障现象</h4><p>   节点状态变为 NotReady</p>
<p>   通过 <code>kubectl describe node x.x.x.x | grep -A10 Conditions</code> 查询，LastHeartbeatTime、LastTransitionTime的状态近期再没有更新过数据。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Conditions:</span><br><span class="line">  Type                 Status    LastHeartbeatTime                 LastTransitionTime                Reason              Message</span><br><span class="line">  ----                 ------    -----------------                 ------------------                ------              -------</span><br><span class="line">  NetworkUnavailable   False     Thu, 06 May 2021 10:24:38 +0800   Thu, 06 May 2021 10:24:38 +0800   FlannelIsUp         Flannel is running on this node</span><br><span class="line">  MemoryPressure       Unknown   Thu, 06 May 2021 13:40:00 +0800   Thu, 06 May 2021 13:41:35 +0800   NodeStatusUnknown   Kubelet stopped posting node status.</span><br><span class="line">  DiskPressure         Unknown   Thu, 06 May 2021 13:40:00 +0800   Thu, 06 May 2021 13:41:35 +0800   NodeStatusUnknown   Kubelet stopped posting node status.</span><br><span class="line">  PIDPressure          Unknown   Thu, 06 May 2021 13:40:00 +0800   Thu, 06 May 2021 13:41:35 +0800   NodeStatusUnknown   Kubelet stopped posting node status.</span><br><span class="line">  Ready                Unknown   Thu, 06 May 2021 13:40:00 +0800   Thu, 06 May 2021 13:41:35 +0800   NodeStatusUnknown   Kubelet stopped posting node status.</span><br></pre></td></tr></table></figure>

<h4 id="触发原因-1"><a href="#触发原因-1" class="headerlink" title="触发原因"></a>触发原因</h4><p>​    该问题是社区的一个 BUG，节点概率性会触发，一旦触发该 BUG 会导致节点无法更新状态。最终导致节点被置为 NotReady。</p>
<h4 id="排查方法-1"><a href="#排查方法-1" class="headerlink" title="排查方法"></a>排查方法</h4><p>  方法一：通过 journalctl 查询 kubelet 日志的是否存在关键字</p>
<p>  方法二：通过查看 messages 日志，过滤相关关键字判断</p>
<p>​    <code>grep -i &quot;use of closed network connection&quot; /var/log/messages</code></p>
<p>  该问题目前在社区的 kubernetes 1.18 版本得到了解决，TKE 3.4.X 版本默认修复了这个问题。在 TKE 3.0.4 通过配置检测脚本来自动重启 kubelet 修复。对于 TKE 3.0.4 之前的版本，可以参考如下链接进行临时规避修复：</p>
<p><a href="https://gdc.lexiangla.com/teams/k100044/docs/c2b199b4780f11ebaee046cd73dfa810?company_from=gdc">https://gdc.lexiangla.com/teams/k100044/docs/c2b199b4780f11ebaee046cd73dfa810?company_from=gdc</a></p>
<h3 id="PLEG-检测失败"><a href="#PLEG-检测失败" class="headerlink" title="PLEG 检测失败"></a>PLEG 检测失败</h3><h4 id="故障现象-2"><a href="#故障现象-2" class="headerlink" title="故障现象"></a>故障现象</h4><p>  如果节点出现了 PLEG 超时的问题，可以观察到这个节点它的 Ready、NotReady 状态的切换会很频繁，处于一个不稳定的状态。</p>
<p>  通过 <code>kubectl describe node x.x.x.x | grep -A10 Conditions</code> 查询到类似的信息。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Conditions:</span><br><span class="line">  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message</span><br><span class="line">  ----                 ------  -----------------                 ------------------                ------                       -------</span><br><span class="line">  NetworkUnavailable   False   Tue, 27 Apr 2021 12:28:53 +0800   Tue, 27 Apr 2021 12:28:53 +0800   FlannelIsUp                  Flannel is running on this node</span><br><span class="line">  MemoryPressure       False   Wed, 28 Apr 2021 23:06:47 +0800   Fri, 23 Apr 2021 01:20:55 +0800   KubeletHasSufficientMemory   kubelet has sufficient memory available</span><br><span class="line">  DiskPressure         True    Wed, 28 Apr 2021 23:06:47 +0800   Wed, 28 Apr 2021 22:41:27 +0800   KubeletHasDiskPressure       kubelet has disk pressure</span><br><span class="line">  PIDPressure          False   Wed, 28 Apr 2021 23:06:47 +0800   Fri, 23 Apr 2021 01:20:55 +0800   KubeletHasSufficientPID      kubelet has sufficient PID available</span><br><span class="line">  Ready                False   Wed, 28 Apr 2021 23:06:47 +0800   Sun, 06 Dec 2020 18:49:40 +0100   KubeletNotReady              PLEG is not healthy: pleg was last seen active 10m18.040734348s ago; threshold is 3m0s</span><br></pre></td></tr></table></figure>

<h4 id="触发原因-2"><a href="#触发原因-2" class="headerlink" title="触发原因"></a>触发原因</h4><p>  PLEG 是 Pod Lifecycle Event Generator（Pod 生命周期事件生成器），它用来周期性收集节点上各个 Pod 的状态，并将 Pod 状态写入到缓存中。让控制器能够根据最新 Pod 的状态进行控制。</p>
<p>  在周期性的 relist（收集容器状态信息）的操作中，如果超出了默认预定的事件阈值（默认 3 分钟），就会触发事件，将 Node 状态切换为 NotReady。</p>
<p>  我们可以简单的理解 relist 的动作就是 docker ps 列出所有容器，再进一步 inspect 这些容器的信息。</p>
<p>  可能导致 relist 超出 3 分钟的原因如下：</p>
<ul>
<li>节点上运行了大量的 Pod，导致 relist 收集超时。</li>
<li>节点的负载较高，性能不足，导致 relist 收集超时。</li>
<li>有部分容器处于 Dead 或者其他状态（如，长时间Create），阻塞 inspect。</li>
</ul>
<h4 id="排查方法-2"><a href="#排查方法-2" class="headerlink" title="排查方法"></a>排查方法</h4><p>  <strong>原因1 节点上运行了大量的 Pod，导致 relist 收集超时。</strong></p>
<p>​    确认该节点的 Pod 运行数量，以及容器数量</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">获取 Pod 数量</span></span><br><span class="line">kubectl get pod -o wide -A | grep -i 节点IP（名称） | wc -l</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">获取 Pod 数量，更简洁的方法</span></span><br><span class="line">kubectl describe node 节点名称 | grep -i Non-terminated</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">获取容器数量</span></span><br><span class="line">docker ps -a | wc -l</span><br></pre></td></tr></table></figure>

<p>  <strong>原因2 节点负载较高，性能不足，导致 relist 收集超时。</strong></p>
<p>​    可以通过判断该节点的负载来确认，通过 top 等指令确认 CPU、内存、IO等负载情况。可以关注一下 wa 的值。如果 wa 值比较大，再通过 iostat 进一步获取 IO 数据。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">top</span></span><br><span class="line">[192.168.7.221 ~ ]# top</span><br><span class="line">top - 14:15:51 up  3:55,  1 user,  load average: 1.41, 0.99, 0.91</span><br><span class="line">Tasks: 348 total,   1 running, 347 sleeping,   0 stopped,   0 zombie</span><br><span class="line"><span class="meta prompt_">%</span><span class="language-bash">Cpu(s):  2.6 us,  1.2 sy,  0.0 ni, 96.2 <span class="built_in">id</span>,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span></span><br><span class="line">KiB Mem : 74012144 total, 35444780 free, 17865776 used, 20701592 buff/cache</span><br><span class="line">KiB Swap: 10485760+total, 10485760+free,        0 used. 55667436 avail Mem</span><br><span class="line"></span><br><span class="line">  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND</span><br><span class="line"> 1880 root      20   0 5479028   2.2g  11216 S  31.2  3.1  86:37.15 qemu-kvm</span><br><span class="line"> 1904 root      20   0 5360192   2.2g  11236 S  18.8  3.2  75:41.94 qemu-kvm</span><br><span class="line">16146 root      20   0 5040564   2.3g  11212 S  18.8  3.3   5:59.33 qemu-kvm</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">iostat</span></span><br><span class="line">[192.168.7.221 ~ ]# iostat -x</span><br><span class="line">Linux 3.10.0-1160.24.1.el7.x86_64 (localhost.localdomain)       05/06/2021      _x86_64_        (24 CPU)</span><br><span class="line"></span><br><span class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</span><br><span class="line">           3.65    0.00    1.37    0.16    0.00   94.82</span><br><span class="line"></span><br><span class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</span><br><span class="line">sda               0.00     0.07    0.39    0.45    14.76     3.83    44.06     0.00    4.66    9.51    0.39   0.85   0.07</span><br><span class="line">sdb               0.00     0.01    6.49  107.14   442.68  1295.89    30.60     0.30    2.68   12.67    2.08   0.12   1.41</span><br><span class="line">dm-0              0.00     0.00    6.49  107.15   442.64  1296.16    30.60     0.31    2.69   12.68    2.09   0.13   1.43</span><br></pre></td></tr></table></figure>

<p>  <strong>原因3 有部分容器处于 Dead 或者其他状态（如，长时间Create）阻塞 inspect。</strong></p>
<p>​    可以通过复现 relist 的行为，来判断卡点，我们可以从 docker ps + docker inspect 执行的来判断是否有阻塞的容器，进一步获取信息。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">到触发了 PLEG 超时的节点上执行如下操作</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">收集是否有卡死的容器</span></span><br><span class="line">for c in $(docker ps -aq); do echo $c; docker inspect $c 1&gt;/dev/null 2&gt;&amp;1; done</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">进一步查看卡死容器的状态，此处 cid 是上一条命令执行获取到的数据。</span></span><br><span class="line">docker ps -a | grep $cid</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">如果状态是 Dead，通过 docker <span class="built_in">rm</span> -f <span class="variable">$cid</span> 来进行处理</span></span><br><span class="line">docker rm -f $cid</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">如果状态是 Create，收集 stack 信息，提供给后端同学进一步分析问题</span></span><br><span class="line">cat /proc/PID/stack</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">另外可以收集一下 dmesg 是否存在相关的内核错误信息。</span></span><br><span class="line">dmesg -T</span><br></pre></td></tr></table></figure>

<p>​    如果在 dmesg 等看到了 XFS 分配内存失败的相关错误信息，还请收集如下信息</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">获取内核版本，注意低于 3.10.1062 的内核版本存在 XFS 碎片的 BUG。</span></span><br><span class="line">uname -r </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查询内存碎片</span></span><br><span class="line">cat /proc/buddyinfo</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">获取 XFS 版本</span></span><br><span class="line">xfs_info</span><br></pre></td></tr></table></figure>

<h3 id="Container-Runtime-故障"><a href="#Container-Runtime-故障" class="headerlink" title="Container Runtime 故障"></a>Container Runtime 故障</h3><h4 id="故障现象-3"><a href="#故障现象-3" class="headerlink" title="故障现象"></a>故障现象</h4><p>  通过 <code>kubectl describe node x.x.x.x | grep -A10 Conditions</code> 查询到类似的信息。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Conditions:</span><br><span class="line">  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message</span><br><span class="line">  ----                 ------  -----------------                 ------------------                ------                       -------</span><br><span class="line">  NetworkUnavailable   False   Thu, 06 May 2021 10:23:35 +0800   Thu, 06 May 2021 10:23:35 +0800   FlannelIsUp                  Flannel is running on this node</span><br><span class="line">  MemoryPressure       False   Thu, 06 May 2021 13:29:26 +0800   Thu, 06 May 2021 09:57:18 +0800   KubeletHasSufficientMemory   kubelet has sufficient memory available</span><br><span class="line">  DiskPressure         False   Thu, 06 May 2021 13:29:26 +0800   Thu, 06 May 2021 09:57:18 +0800   KubeletHasNoDiskPressure     kubelet has no disk pressure</span><br><span class="line">  PIDPressure          False   Thu, 06 May 2021 13:29:26 +0800   Thu, 06 May 2021 09:57:18 +0800   KubeletHasSufficientPID      kubelet has sufficient PID available</span><br><span class="line">  Ready                False   Thu, 06 May 2021 13:29:26 +0800   Thu, 06 May 2021 13:28:55 +0800   KubeletNotReady              [container runtime is down, container runtime not ready: RuntimeReady=false reason:DockerDaemonNotReady message:docker: failed to get docker version: Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?]</span><br></pre></td></tr></table></figure>

<h4 id="触发原因-3"><a href="#触发原因-3" class="headerlink" title="触发原因"></a>触发原因</h4><p>  通过 Conditions 中的 KubeletNotReady Reason 可以得知，这是因为连接 docker 失败导致的。</p>
<h4 id="排查方法-3"><a href="#排查方法-3" class="headerlink" title="排查方法"></a>排查方法</h4><p>​    获取 docker 状态是否为 Running，如果不是 Running，收集 docker 的日志来进一步排查，同时也可以尝试手动拉起修复 docker。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查询 docker 运行状态</span></span><br><span class="line">systemctl status docker</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">收集 docker 日志</span></span><br><span class="line">journalctl -u docker &gt; docker-$(date +&quot;%Y%m%d-%H%M%S&quot;).log</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">手动启动 docker</span></span><br><span class="line">systemctl start docker</span><br></pre></td></tr></table></figure>

<h3 id="节点网络不通"><a href="#节点网络不通" class="headerlink" title="节点网络不通"></a>节点网络不通</h3><h4 id="故障现象-4"><a href="#故障现象-4" class="headerlink" title="故障现象"></a>故障现象</h4><p>   通过 <code>kubectl describe node x.x.x.x | grep -A10 Conditions</code> 查询，LastHeartbeatTime、LastTransitionTime的状态近期再没有更新过数据。</p>
<p>   因为节点与控制器之间的网络不通，状态无法上报给控制器，这个时候 describe 出的结果和 kubelet(golang) BUG 触发的现象类似。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Conditions:</span><br><span class="line">  Type                 Status    LastHeartbeatTime                 LastTransitionTime                Reason              Message</span><br><span class="line">  ----                 ------    -----------------                 ------------------                ------              -------</span><br><span class="line">  NetworkUnavailable   False     Thu, 06 May 2021 10:24:38 +0800   Thu, 06 May 2021 10:24:38 +0800   FlannelIsUp         Flannel is running on this node</span><br><span class="line">  MemoryPressure       Unknown   Thu, 06 May 2021 13:40:00 +0800   Thu, 06 May 2021 13:41:35 +0800   NodeStatusUnknown   Kubelet stopped posting node status.</span><br><span class="line">  DiskPressure         Unknown   Thu, 06 May 2021 13:40:00 +0800   Thu, 06 May 2021 13:41:35 +0800   NodeStatusUnknown   Kubelet stopped posting node status.</span><br><span class="line">  PIDPressure          Unknown   Thu, 06 May 2021 13:40:00 +0800   Thu, 06 May 2021 13:41:35 +0800   NodeStatusUnknown   Kubelet stopped posting node status.</span><br><span class="line">  Ready                Unknown   Thu, 06 May 2021 13:40:00 +0800   Thu, 06 May 2021 13:41:35 +0800   NodeStatusUnknown   Kubelet stopped posting node status.</span><br></pre></td></tr></table></figure>

<h4 id="触发原因-4"><a href="#触发原因-4" class="headerlink" title="触发原因"></a>触发原因</h4><p>  可能是节点下线或者因为其他原因导致网络阻塞，节点无法与控制器正常通信。</p>
<h4 id="排查方法-4"><a href="#排查方法-4" class="headerlink" title="排查方法"></a>排查方法</h4><p>  确认目标节点是否存活，如果存活的话，进一步测试该节点与其他节点之间的连通性。是否有可能是防火墙或者其他因素阻塞了连通性。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">确认目标节点是否存活</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在其他节点执行如下操作</span></span><br><span class="line">ping 目标节点IP</span><br><span class="line">ssh 目标节点IP</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">如果目标节点存活，进一步排查它与其他节点之间的连通性。</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">登录到目标节点执行如下操作</span></span><br><span class="line">ping 其他节点地址</span><br><span class="line">curl apiserver:6443</span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>K8S</tag>
      </tags>
  </entry>
  <entry>
    <title>about</title>
    <url>/2024/01/25/about/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>基于资源对应 pod 批量执行 kubectl logs 采集工具</title>
    <url>/2024/01/23/kubectl%20logs%20%E6%97%A5%E5%BF%97%E9%87%87%E9%9B%86%E5%B7%A5%E5%85%B7/</url>
    <content><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>  在交付运维阶段，有时候在日志平台还没有就绪，或者日志平台有问题情况下，我们需要对 Pod 进行诊断，这时候可能需要去读取 pod 的标准输出。但是一般情况下环境的 Pod 都是多副本高可用的，服务的请求可能会随机落到任意 Pod。对此通常的解决方法是拉多个窗口去观测，这种方式不大方便。这里就通过开发一个简易日志采集脚本来简化改工作。</p>
<h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><p>  实际上我只需要获取 pod 的清单，然后挨个 pod 执行 kubectl logs 的指令，并挂在后台。然后再通过 tail 命令去获取所有 log 的输出即可。本身 tail 对多个文件的输出是自带了 title。可以简化工作量。</p>
<p>  获取 pod 清单的方式是让使用者输入 pod 控制器的类型（deployment、daemonset等等或者简写），命名空间，对应控制器资源的名称，每个控制器都是通过标签选择来判断 pod 是否在集群中满足数量。所以这里通过获取控制器的 matchlabels 来生成判断条件。后续通过 kubectl get pod -l 标签的方式就能直接拿到清单了。</p>
<p>  考虑到日志的展示本身就是需要生成临时日志文件，并事后可能需要保存，或者多次执行，脚本会自动创建一个命名空间+资源名称的目录，来存储日志文件。并加入一些删除的逻辑，强制退出脚本或者启动脚本时都会检查 kubectl logs 的进程还有没有运行在环境，如果有就删除残留的进程。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line">print_log()</span><br><span class="line">&#123;</span><br><span class="line">    log_level=$1</span><br><span class="line">    log_msg=$2</span><br><span class="line">    currentTime=&quot;$(date &#x27;+%F %T&#x27;)&quot;</span><br><span class="line">    echo &quot;$currentTime    [$log_level]    $log_msg&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">clear() &#123;</span><br><span class="line">    if [ -f clearlist ]; then</span><br><span class="line">        while IFS= read -r line; do</span><br><span class="line">          if [ $(ps aux | grep &quot;$&#123;line&#125;&quot; | wc -l) -gt 1 ] ; then</span><br><span class="line">            ps aux | grep &quot;$&#123;line&#125;&quot; | grep -v grep | awk &#x27;&#123; print $2 &#125;&#x27; | xargs kill</span><br><span class="line">          fi</span><br><span class="line">        done &lt; clearlist</span><br><span class="line">    fi</span><br><span class="line">    rm -f clearlist</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">ctrl_c() &#123;</span><br><span class="line">    clear</span><br><span class="line">    print_log &quot;INFO&quot; &quot;Is k8s_log_collector.sh: line xx:  xxxx Terminated appeared, please ingore.&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">trap ctrl_c INT</span><br><span class="line"></span><br><span class="line">baseName=$(basename &quot;$0&quot;)</span><br><span class="line"></span><br><span class="line">if [ $# -lt 3 ]; then</span><br><span class="line">    print_log &quot;INFO&quot; &quot;usage: $baseName resource ns name&quot;</span><br><span class="line">    print_log &quot;INFO&quot; &quot;Example:&quot;</span><br><span class="line">    print_log &quot;INFO&quot; &quot;  $baseName ds kube-flannel kube-flannel-ds&quot;</span><br><span class="line">    print_log &quot;INFO&quot; &quot;  $baseName deploy default nginx&quot;</span><br><span class="line">    exit 1</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">if ! kubectl get $1 -n $2 $3 &amp;&gt; /dev/null; then</span><br><span class="line">    echo &quot;resource not exits.&quot;</span><br><span class="line">    exit 1</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">log_path=log_collect/$2/$1_$2_$3/</span><br><span class="line">if [ -d log_collect/$2 ]; then</span><br><span class="line">    clear</span><br><span class="line">    mv log_collect/$2 log_collect/$2_$(date +%Y%d%H%M%T)</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">mkdir -p $&#123;log_path&#125;</span><br><span class="line"></span><br><span class="line">labels=$(kubectl get $1 -n $2 $3 -o jsonpath=&quot;&#123;.spec.selector.matchLabels&#125;&quot;  | sed &#x27;s/&#123;//&#x27; | sed &#x27;s/&#125;//&#x27; | sed &#x27;s/&quot;//g&#x27; | sed &#x27;s/:/=/g&#x27;)</span><br><span class="line"></span><br><span class="line">podlist=$(kubectl get pod -n $2 -l $&#123;labels&#125; --no-headers | awk &#x27;&#123; print $1 &#125;&#x27;)</span><br><span class="line"></span><br><span class="line">for pod in $&#123;podlist&#125;</span><br><span class="line">do</span><br><span class="line">    echo &quot;kubectl logs -n $2 $&#123;pod&#125;&quot; &gt;&gt; clearlist</span><br><span class="line">    kubectl logs -n $2 $&#123;pod&#125; -f &amp;&gt; $&#123;log_path&#125;/$&#123;pod&#125;.log &amp;</span><br><span class="line">done</span><br><span class="line"></span><br><span class="line">print_log &quot;INFO&quot; &quot;Log collection started, wait for 2 seconds.&quot;</span><br><span class="line">sleep 2</span><br><span class="line"></span><br><span class="line">tail -f $&#123;log_path&#125;/*</span><br></pre></td></tr></table></figure>

<p>  效果预览：</p>
<img src="/2024/01/23/kubectl%20logs%20%E6%97%A5%E5%BF%97%E9%87%87%E9%9B%86%E5%B7%A5%E5%85%B7/1.png" class="" title="1.png">

<p>  目前初版只是简单的实现了功能，整体逻辑和功能还比较搓。后续代码在 orca-tools 中继续维护。</p>
]]></content>
      <tags>
        <tag>K8S</tag>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title>chrony主机时钟同步</title>
    <url>/2020/09/25/chrony%E4%B8%BB%E6%9C%BA%E6%97%B6%E9%92%9F%E5%90%8C%E6%AD%A5/</url>
    <content><![CDATA[<ol>
<li>安装 chrony</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum -y install chrony</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>配置 chrony</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vi /etc/chrony.conf</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">找到 server 区块，全注释，替换为 aliyun 时钟源</span></span><br><span class="line"></span><br><span class="line">server ntp1.aliyun.com iburst</span><br><span class="line">server ntp2.aliyun.com iburst</span><br><span class="line">server ntp3.aliyun.com iburst</span><br><span class="line">server ntp4.aliyun.com iburst</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>启动 chrony 并设置开机自启动</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl enable chronyd</span><br><span class="line">systemctl start chronyd</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>修改时区、查看时区</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">设置时区为上海</span></span><br><span class="line">timedatectl set-timezone Asia/Shanghai</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看当前时区和时钟同步情况</span></span><br><span class="line">timedatectl status</span><br></pre></td></tr></table></figure>

<ol start="5">
<li>配置硬件时钟和系统时钟一致</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">如果是配置系统时钟和硬件时钟保持一致，则可以使用 -s 参数</span></span><br><span class="line">hwclock -w</span><br></pre></td></tr></table></figure>

<ol start="6">
<li>chronyc 运维指令</li>
</ol>
<p><strong>查看当前机器同步的 ntp 服务器</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">chronyc sources -v</span><br></pre></td></tr></table></figure>

<p>  示例输出：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@cloud-master01 kube-prometheus]# chronyc sources -v</span><br><span class="line">210 Number of sources = 1</span><br><span class="line"></span><br><span class="line">  .-- Source mode  &#x27;^&#x27; = server, &#x27;=&#x27; = peer, &#x27;#&#x27; = local clock.</span><br><span class="line"> / .- Source state &#x27;*&#x27; = current synced, &#x27;+&#x27; = combined , &#x27;-&#x27; = not combined,</span><br><span class="line">| /   &#x27;?&#x27; = unreachable, &#x27;x&#x27; = time may be in error, &#x27;~&#x27; = time too variable.</span><br><span class="line">||                                                 .- xxxx [ yyyy ] +/- zzzz</span><br><span class="line">||      Reachability register (octal) -.           |  xxxx = adjusted offset,</span><br><span class="line">||      Log2(Polling interval) --.      |          |  yyyy = measured offset,</span><br><span class="line">||                                \     |          |  zzzz = estimated error.</span><br><span class="line">||                                 |    |           \</span><br><span class="line">MS Name/IP address         Stratum Poll Reach LastRx Last sample</span><br><span class="line">===============================================================================</span><br><span class="line">^* 120.25.115.20                 2   6   337    64   -550us[ -759us] +/- 9876us</span><br></pre></td></tr></table></figure>

<p><strong>查看 ntp 服务器状态</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">chronyc sourcestats -v</span><br></pre></td></tr></table></figure>

<p>  示例输出</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">210 Number of sources = 1</span><br><span class="line">                             .- Number of sample points in measurement set.</span><br><span class="line">                            /    .- Number of residual runs with same sign.</span><br><span class="line">                           |    /    .- Length of measurement set (time).</span><br><span class="line">                           |   |    /      .- Est. clock freq error (ppm).</span><br><span class="line">                           |   |   |      /           .- Est. error in freq.</span><br><span class="line">                           |   |   |     |           /         .- Est. offset.</span><br><span class="line">                           |   |   |     |          |          |   On the -.</span><br><span class="line">                           |   |   |     |          |          |   samples. \</span><br><span class="line">                           |   |   |     |          |          |             |</span><br><span class="line">Name/IP Address            NP  NR  Span  Frequency  Freq Skew  Offset  Std Dev</span><br><span class="line">==============================================================================</span><br><span class="line">120.25.115.20              11   9   525     -0.053      8.843  -6245ns  1074us</span><br></pre></td></tr></table></figure>

<p><strong>查看 ntp 服务器是否在线</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">chronyc activity -v</span><br></pre></td></tr></table></figure>

<p>  示例输出：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@cloud-master01 kube-prometheus]# chronyc activity -v</span><br><span class="line">200 OK</span><br><span class="line">1 sources online</span><br><span class="line">0 sources offline</span><br><span class="line">0 sources doing burst (return to online)</span><br><span class="line">0 sources doing burst (return to offline)</span><br><span class="line">0 sources with unknown address</span><br></pre></td></tr></table></figure>

<p><strong>查看 ntp 服务器详细信息</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">chronyc tracking -v</span><br></pre></td></tr></table></figure>

<p>  示例输出：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@cloud-master01 kube-prometheus]# chronyc tracking -v</span><br><span class="line">Reference ID    : 78197314 (120.25.115.20)</span><br><span class="line">Stratum         : 3</span><br><span class="line">Ref time (UTC)  : Fri Oct 06 14:40:05 2023</span><br><span class="line">System time     : 0.000293604 seconds fast of NTP time</span><br><span class="line">Last offset     : +0.000001403 seconds</span><br><span class="line">RMS offset      : 0.000997817 seconds</span><br><span class="line">Frequency       : 6.722 ppm fast</span><br><span class="line">Residual freq   : +0.016 ppm</span><br><span class="line">Skew            : 4.444 ppm</span><br><span class="line">Root delay      : 0.013335334 seconds</span><br><span class="line">Root dispersion : 0.001928344 seconds</span><br><span class="line">Update interval : 65.3 seconds</span><br><span class="line">Leap status     : Normal</span><br></pre></td></tr></table></figure>

<p><strong>强制同步系统时钟</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">chronyc -a makestep</span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>NTP</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes 快速拉起单节点集群</title>
    <url>/2024/01/16/kubernetes%20%E5%8D%95%E8%8A%82%E7%82%B9%E5%BF%AB%E9%80%9F%E5%AE%89%E8%A3%85/</url>
    <content><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>  考虑到近期会做多 Kubernetes 集群相关的一些验证，需要频繁创建单机版的 K8S 集群。需要编写一个简单的自动化 K8S 安装脚本。</p>
<h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><p>  基于社区 Kubernetes 提供的安装步骤，做了一下简单的脚本自动化封装。初版内容如下</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">用于实现单节点部署 K8S，仅用于部署调试、开发环境，验证于 CentOS 7.9 环境</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">部署后使用默认 K8S CIDR，机器主机名称修改为 K8S-Master01，并且安装 flannel。</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">适用于国区</span></span><br><span class="line"></span><br><span class="line">init_repo() &#123;</span><br><span class="line">    cat &gt; /etc/yum.repos.d/kubernetes.repo &lt;&lt; EOF</span><br><span class="line">[kubernetes]</span><br><span class="line">name=Kubernetes</span><br><span class="line">baseurl=https://pkgs.k8s.io/core:/stable:/v1.29/rpm/</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=1</span><br><span class="line">gpgkey=https://pkgs.k8s.io/core:/stable:/v1.29/rpm/repodata/repomd.xml.key</span><br><span class="line">EOF</span><br><span class="line">    yum -y install yum-utils</span><br><span class="line">    yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">install_pkg() &#123;</span><br><span class="line">    yum -y install kubelet kubeadm containerd kubectl</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">config_ntp() &#123;</span><br><span class="line">    yum -y install chrony</span><br><span class="line">    sed -i &#x27;/server/ d&#x27; /etc/chrony.conf</span><br><span class="line">    echo &quot;server ntp1.aliyun.com iburst&quot; &gt;&gt; /etc/chrony.conf</span><br><span class="line">    systemctl enable chronyd</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">crictl_init() &#123;</span><br><span class="line">    cat &gt; /etc/crictl.yaml &lt;&lt;EOF</span><br><span class="line">runtime-endpoint: unix:///var/run/containerd/containerd.sock</span><br><span class="line">image-endpoint: unix:///var/run/containerd/containerd.sock</span><br><span class="line">timeout: 0</span><br><span class="line">debug: false</span><br><span class="line">pull-image-on-create: false</span><br><span class="line">EOF</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">init_containerd() &#123;</span><br><span class="line">    containerd config default &gt; /etc/containerd/config.toml</span><br><span class="line">    sed -i &#x27;s/registry.k8s.io/registry.aliyuncs.com\/google_containers/&#x27; /etc/containerd/config.toml</span><br><span class="line">    systemctl restart containerd</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">service_onboot() &#123;</span><br><span class="line">    systemctl enable containerd</span><br><span class="line">    systemctl enable kubelet</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">disable_swap() &#123;</span><br><span class="line">    swapoff -a</span><br><span class="line">    sed -i &#x27;/swap/ s/^/#/g&#x27;  /etc/fstab</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">根据默认网关出接口的 IP 配置 hosts</span></span><br><span class="line">init_etchosts() &#123;</span><br><span class="line">    netif=$(ip route show | grep default | awk &#x27;&#123; print $5 &#125;&#x27;)</span><br><span class="line">    ipaddr=$(ip addr show $&#123;netif&#125; | grep -w inet | awk &#x27;&#123;print $2&#125;&#x27; | awk -F&#x27;/&#x27; &#x27;&#123; print $1 &#125;&#x27;)</span><br><span class="line">    echo &#x27;$&#123;ipaddr&#125; k8s-master01&#x27; &gt;&gt; /etc/hosts</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">init_sysctl() &#123;</span><br><span class="line">  cat &lt;&lt;EOF | sudo tee /etc/modules-load.d/k8s.conf</span><br><span class="line">overlay</span><br><span class="line">br_netfilter</span><br><span class="line">EOF</span><br><span class="line">    modprobe overlay</span><br><span class="line">    modprobe br_netfilter</span><br><span class="line">  cat &lt;&lt;EOF | sudo tee /etc/sysctl.d/k8s.conf</span><br><span class="line">net.bridge.bridge-nf-call-iptables  = 1</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">net.ipv4.ip_forward                 = 1</span><br><span class="line">EOF</span><br><span class="line">    sysctl --system</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">k8s_install() &#123;</span><br><span class="line">    kubeadm init --pod-network-cidr=10.244.0.0/16 --image-repository=registry.aliyuncs.com/google_containers --node-name k8s-master01</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">k8s_post() &#123;</span><br><span class="line">    mkdir -p /root/.kube</span><br><span class="line">    cp -a /etc/kubernetes/admin.conf /root/.kube/config</span><br><span class="line">    kubectl taint node k8s-master01 node-role.kubernetes.io/control-plane-</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">install_flannel() &#123;</span><br><span class="line">    wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml</span><br><span class="line">    kubectl apply -f kube-flannel.yml</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">init() &#123;</span><br><span class="line">    init_repo</span><br><span class="line">    install_pkg</span><br><span class="line">    crictl_init</span><br><span class="line">    disable_swap</span><br><span class="line">    service_onboot</span><br><span class="line">    init_containerd</span><br><span class="line">    init_sysctl</span><br><span class="line">    init_etchosts</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">install() &#123;</span><br><span class="line">    k8s_install</span><br><span class="line">    k8s_post</span><br><span class="line">    install_flannel</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">main() &#123;</span><br><span class="line">    init</span><br><span class="line">    install</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">main</span><br></pre></td></tr></table></figure>

<p>  填入文件 k8s_install.sh，直接执行脚本即可完成安装。执行 bash k8s_install.sh，就会自动创建出一个单节点的。</p>
<p>  目前实现的非常简单，不考虑任何变化，逻辑判断也比较宽松，后续变动继续在 orca-tools 维护。</p>
]]></content>
      <tags>
        <tag>K8S</tag>
      </tags>
  </entry>
  <entry>
    <title>排查 kubectl edit 保存失败方法</title>
    <url>/2022/08/23/%E6%8E%92%E6%9F%A5%20kubectl%20edit%20%E4%BF%9D%E5%AD%98%E5%A4%B1%E8%B4%A5%E6%80%9D%E8%B7%AF/</url>
    <content><![CDATA[<h2 id="1-常见原因"><a href="#1-常见原因" class="headerlink" title="1. 常见原因"></a><strong>1. 常见原因</strong></h2><p>保存失败的常见原因如下：</p>
<ul>
<li><p>使用 tab 产生空白字符。</p>
</li>
<li><p>使用了无效的选项、参数等。</p>
</li>
<li><p>value 未使用字符串。</p>
</li>
<li><p>环境的 kubernetes 配置了 webhook，提交 YAML 修改到 apiserver 以后需要完成校验，如果校验失败或 webhook 的组件故障，此时 kubectl edit 保存会失败。</p>
</li>
</ul>
<h2 id="2-排查思路"><a href="#2-排查思路" class="headerlink" title="2. 排查思路"></a><strong>2. 排查思路</strong></h2><p>  通过 kubectl edit 保存配置时，如果使用了无效的参数或者语法错误。将会打印相印的错误提示，错误提示的行首有 # 的字符。根据这些提示即可找到故障原因。</p>
<p>  另一种问题是，保存 YAML 时未产生错误提示，但是保存后产生了类似如下的错误提示 dial tcp: lookup ti-resource-server.ti-base.svc.cluster.local on [::1]:53: dial udp [::1]:53: connect: network is unreachable。这种场景通常是因为 webhook 组件故障引起的。需要解决 webhook 组件故障。</p>
<h2 id="3-常见错误原因"><a href="#3-常见错误原因" class="headerlink" title="3. 常见错误原因"></a><strong>3. 常见错误原因</strong></h2><h3 id="3-1-did-not-find-expected-key"><a href="#3-1-did-not-find-expected-key" class="headerlink" title="3.1 did not find expected key"></a><strong>3.1 did not find expected key</strong></h3><p>  如果看见 did not find expected key 的错误，通常是空格数量不正确导致的。上下级选项需要保持两个空格。</p>
<h3 id="3-2-The-edited-file-failed-validation"><a href="#3-2-The-edited-file-failed-validation" class="headerlink" title="3.2 The edited file failed validation"></a><strong>3.2 The edited file failed validation</strong></h3><p>  如果看见类似 invalid value: “The edited file failed validation”: ValidationError(Deployment.spec): unknown field “12345” in io.k8s.api.apps.v1.DeploymentSpec 的错误，通常是使用了错误的选项。可以通过 kubectl explain 资源.spec.选项名称 来获取有效合法的 key、values 值。</p>
<h3 id="3-3-cannot-convert-int64-to-string"><a href="#3-3-cannot-convert-int64-to-string" class="headerlink" title="3.3 cannot convert int64 to string"></a><strong>3.3 cannot convert int64 to string</strong></h3><p>  未使用”” 将整型数据括起来。常见于添加 nodeSelector 未给 value 配置 “”。</p>
<h3 id="3-4-no-matches-for-kind-“xxxx”-in-version-“xxxx”"><a href="#3-4-no-matches-for-kind-“xxxx”-in-version-“xxxx”" class="headerlink" title="3.4 no matches for kind “xxxx” in version “xxxx”"></a><strong>3.4 no matches for kind “xxxx” in version “xxxx”</strong></h3><p>  如果看见类似 The edited file had a syntax error: unable to recognize “edited-file”: no matches for kind “Deployment” in version “extension&#x2F;v1beta1” 的错误，通常是 YAML 编辑的资源使用了错误的 apiVersion 导致的。同样可以通过 kubectl explain 指令来获取对应资源的 apiVersion 可用版本。</p>
<h3 id="3-5-provided-port-is-not-in-the-valid-range-The-range-of-valid-ports-is-xxxx-xxxx"><a href="#3-5-provided-port-is-not-in-the-valid-range-The-range-of-valid-ports-is-xxxx-xxxx" class="headerlink" title="3.5 provided port is not in the valid range. The range of valid ports is xxxx-xxxx"></a><strong>3.5 provided port is not in the valid range. The range of valid ports is xxxx-xxxx</strong></h3><p>  只存在于 service 修改的场景，如果看见类似于 * spec.ports[0].nodePort: Invalid value: 10508: provided port is not in the valid range. The range of valid ports is 30000-32767 的操作，代表修改 service 配置的 NodePort 超出了 kube-apiserver 中 –service-node-port-range 定义的范围，这个范围默认值是 30000-32767，也就是说 NodePort 配置的端口不能超出这个范围。</p>
]]></content>
      <tags>
        <tag>K8S</tag>
      </tags>
  </entry>
  <entry>
    <title>kubernetes go开发环境安装</title>
    <url>/2024/01/26/go%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E7%8E%AF%E5%A2%83/</url>
    <content><![CDATA[<h2 id="go-安装"><a href="#go-安装" class="headerlink" title="go 安装"></a>go 安装</h2><p>wget <a href="https://dl.google.com/go/go1.21.6.linux-amd64.tar.gz">https://dl.google.com/go/go1.21.6.linux-amd64.tar.gz</a> tar xvf go1.21.6.linux-amd64.tar.gz<br>mv go &#x2F;usr&#x2F;local&#x2F;go<br>echo “PATH&#x3D;PATH:&#x2F;usr&#x2F;local&#x2F;go&#x2F;bin” &gt;&gt; &#x2F;etc&#x2F;profile<br>source &#x2F;etc&#x2F;profile</p>
<h2 id="使用国内代理"><a href="#使用国内代理" class="headerlink" title="使用国内代理"></a>使用国内代理</h2><p>go env -w GOPROXY&#x3D;<a href="https://goproxy.cn,direct/">https://goproxy.cn,direct</a></p>
<p>go env -w GO111MODULE&#x3D;auto</p>
]]></content>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title>如何查看某进程建立的连接信息</title>
    <url>/2022/09/10/%E5%A6%82%E4%BD%95%E6%9F%A5%E7%9C%8B%E6%9F%90%E8%BF%9B%E7%A8%8B%E5%BB%BA%E7%AB%8B%E7%9A%84%E8%BF%9E%E6%8E%A5%E4%BF%A1%E6%81%AF/</url>
    <content><![CDATA[<p>  有些场景下，我们需要了解某个进程正在和哪些服务建立连接。本文主要是记录了捕获进程连接信息的几个实现方法。</p>
<h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><h3 id="ss-指令"><a href="#ss-指令" class="headerlink" title="ss 指令"></a>ss 指令</h3><p>最先想到的方法是通过 netstat 或者 ss 的工具去持续查看机器的连接建立情况，并查看 PID 或者进程名称，参见如下</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">获取 sshd 进程的连接情况</span></span><br><span class="line">[root@10 ~]# ss -t  -p | grep sshd</span><br><span class="line">ESTAB      0      0      10.0.2.15:ssh                  10.0.2.15:42700                 users:((&quot;sshd&quot;,pid=2615,fd=3))</span><br><span class="line">ESTAB      0      0      192.168.214.254:ssh                  192.168.214.1:56070                 users:((&quot;sshd&quot;,pid=2863,fd=3))</span><br><span class="line">ESTAB      0      36     192.168.214.254:ssh                  192.168.214.1:56068                 users:((&quot;sshd&quot;,pid=2859,fd=3))考虑</span><br></pre></td></tr></table></figure>

<p>考虑到进程的连接信息是会持续变化的，可通过 while 的方法循环去查看某个进程的连接情况，实现类似 top 的效果</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">while true ; do clear ; ss -t  -p | grep sshd ; sleep 1; done</span><br></pre></td></tr></table></figure>

<h3 id="audit-日志"><a href="#audit-日志" class="headerlink" title="audit 日志"></a>audit 日志</h3><p>  ss 指令的局限在于它没办法回溯历史，你只能查看到当前正在建立的连接信息。但是某些场景下，我们可能需要知道某个进程曾经和哪些机器建立过。这时候就可以借助 audit 日志</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@10 ~]# tail /var/log/audit/audit.log</span><br><span class="line">type=CRYPTO_KEY_USER msg=audit(1703823116.926:813): pid=2872 uid=0 auid=0 ses=89 subj=unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023 msg=&#x27;op=destroy kind=server fp=SHA256:83:79:c8:32:03:bd:25:7b:54:54:f7:b9:99:2b:3d:c4:0d:d9:55:ed:6c:11:a2:8f:e9:b8:ba:0f:4c:18:8c:6f direction=? spid=2872 suid=0  exe=&quot;/usr/sbin/sshd&quot; hostname=10.0.2.15 addr=? terminal=pts/1 res=success&#x27;</span><br></pre></td></tr></table></figure>

<p>  可以看到 audit 的审计是可以记录进程的相关信息，此处记录了进程和谁互联。当然 audit 使用的前提是系统打开了该功能。</p>
<h3 id="perf-工具"><a href="#perf-工具" class="headerlink" title="perf 工具"></a>perf 工具</h3><p>  perf 工具可以用来追踪特定进程建立连接的信息，参考如下方法</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">捕获信息</span></span><br><span class="line">perf record -e &#x27;syscalls:sys_enter_connect&#x27; -p &lt;进程名称&gt;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看捕获结果</span></span><br><span class="line">perf report</span><br></pre></td></tr></table></figure>

<h3 id="lsof-工具"><a href="#lsof-工具" class="headerlink" title="lsof 工具"></a>lsof 工具</h3><p>  lsof 工具可以列出指定进程正在和谁建立连接，和 ss 类似</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">2615 是 PID，根据实际情况调整</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">也可以用 -c 参数替代，-c 参数为追踪的 <span class="built_in">command</span></span></span><br><span class="line">[root@10 ~]# lsof -i -a -p 2615</span><br><span class="line">COMMAND  PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAME</span><br><span class="line">sshd    2615 root    3u  IPv4  32428      0t0  TCP 10.0.2.15:ssh-&gt;10.0.2.15:42700 (ESTABLISHED)</span><br></pre></td></tr></table></figure>

<p>  同样可以通过 while 循环实现持续查看状态</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">while true ; do clear ; lsof -i -a -p 2615 ; sleep 1; done</span><br></pre></td></tr></table></figure>

<h3 id="strace-工具"><a href="#strace-工具" class="headerlink" title="strace 工具"></a>strace 工具</h3><p>  strace 工具是非常强大的链路追踪工具，可以通过 strace 对运行中的进程或者某个命令的执行过程进行追踪。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">使用 trace=network 可以列出网络相关的追踪信息</span></span><br><span class="line">[root@10 ~]# strace -e trace=network curl www.baidu.com</span><br><span class="line">socket(AF_INET6, SOCK_DGRAM, IPPROTO_IP) = 3</span><br><span class="line">socket(AF_INET, SOCK_STREAM, IPPROTO_TCP) = 3</span><br><span class="line">setsockopt(3, SOL_SOCKET, SO_KEEPALIVE, [1], 4) = 0</span><br><span class="line">setsockopt(3, SOL_TCP, TCP_KEEPIDLE, [60], 4) = 0</span><br><span class="line">setsockopt(3, SOL_TCP, TCP_KEEPINTVL, [60], 4) = 0</span><br><span class="line">connect(3, &#123;sa_family=AF_INET, sin_port=htons(80), sin_addr=inet_addr(&quot;120.232.145.144&quot;)&#125;, 16) = -1 EINPROGRESS (Operation now in progress)</span><br><span class="line">getsockopt(3, SOL_SOCKET, SO_ERROR, [0], [4]) = 0</span><br><span class="line">getpeername(3, &#123;sa_family=AF_INET, sin_port=htons(80), sin_addr=inet_addr(&quot;120.232.145.144&quot;)&#125;, [128-&gt;16]) = 0</span><br><span class="line">getsockname(3, &#123;sa_family=AF_INET, sin_port=htons(43260), sin_addr=inet_addr(&quot;10.0.2.15&quot;)&#125;, [128-&gt;16]) = 0</span><br><span class="line">sendto(3, &quot;GET / HTTP/1.1\r\nUser-Agent: curl&quot;..., 77, MSG_NOSIGNAL, NULL, 0) = 77</span><br><span class="line">recvfrom(3, &quot;HTTP/1.1 200 OK\r\nAccept-Ranges: &quot;..., 16384, 0, NULL, NULL) = 2781</span><br><span class="line">&lt;!DOCTYPE html&gt;</span><br><span class="line">&lt;!--STATUS OK--&gt;&lt;html&gt; &lt;head&gt;&lt;meta http-equiv=content-type content=text/html;charset=utf-8&gt;&lt;meta http-equiv=X-UA-Compatible content=IE=Edge&gt;&lt;meta content=always name=referrer&gt;&lt;link rel=stylesheet type=text/css href=http://s1.bdstatic.com/r/www/cache/bdorz/baidu.min.css&gt;&lt;title&gt;百度一下，你就知道&lt;/title&gt;&lt;/head&gt; &lt;body link=#0000cc&gt; &lt;div id=wrapper&gt; &lt;div id=head&gt; &lt;div class=head_wrapper&gt; &lt;div class=s_form&gt; &lt;div class=s_form_wrapper&gt; &lt;div id=lg&gt; &lt;img hidefocus=true src=//www.baidu.com/img/bd_logo1.png width=270 height=129&gt; &lt;/div&gt; &lt;form id=form name=f action=//www.baidu.com/s class=fm&gt; &lt;input type=hidden name=bdorz_come value=1&gt; &lt;input type=hidden name=ie value=utf-8&gt; &lt;input type=hidden name=f value=8&gt; &lt;input type=hidden name=rsv_bp value=1&gt; &lt;input type=hidden name=rsv_idx value=1&gt; &lt;input type=hidden name=tn value=baidu&gt;&lt;span class=&quot;bg s_ipt_wr&quot;&gt;&lt;input id=kw name=wd class=s_ipt value maxlength=255 autocomplete=off autofocus&gt;&lt;/span&gt;&lt;span class=&quot;bg s_btn_wr&quot;&gt;&lt;input type=submit id=su value=百度一下 class=&quot;bg s_btn&quot;&gt;&lt;/span&gt; &lt;/form&gt; &lt;/div&gt; &lt;/div&gt; &lt;div id=u1&gt; &lt;a href=http://news.baidu.com name=tj_trnews class=mnav&gt;新闻&lt;/a&gt; &lt;a href=http://www.hao123.com name=tj_trhao123 class=mnav&gt;hao123&lt;/a&gt; &lt;a href=http://map.baidu.com name=tj_trmap class=mnav&gt;地图&lt;/a&gt; &lt;a href=http://v.baidu.com name=tj_trvideo class=mnav&gt;视频&lt;/a&gt; &lt;a href=http://tieba.baidu.com name=tj_trtieba class=mnav&gt;贴吧&lt;/a&gt; &lt;noscript&gt; &lt;a href=http://www.baidu.com/bdorz/login.gif?login&amp;tpl=mn&amp;u=http%3A%2F%2Fwww.baidu.com%2f%3fbdorz_come%3d1 name=tj_login class=lb&gt;登录&lt;/a&gt; &lt;/noscript&gt; &lt;script&gt;document.write(&#x27;&lt;a href=&quot;http://www.baidu.com/bdorz/login.gif?login&amp;tpl=mn&amp;u=&#x27;+ encodeURIComponent(window.location.href+ (window.location.search === &quot;&quot; ? &quot;?&quot; : &quot;&amp;&quot;)+ &quot;bdorz_come=1&quot;)+ &#x27;&quot; name=&quot;tj_login&quot; class=&quot;lb&quot;&gt;登录&lt;/a&gt;&#x27;);&lt;/script&gt; &lt;a href=//www.baidu.com/more/ name=tj_briicon class=bri style=&quot;display: block;&quot;&gt;更多产品&lt;/a&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div id=ftCon&gt; &lt;div id=ftConw&gt; &lt;p id=lh&gt; &lt;a href=http://home.baidu.com&gt;关于百度&lt;/a&gt; &lt;a href=http://ir.baidu.com&gt;About Baidu&lt;/a&gt; &lt;/p&gt; &lt;p id=cp&gt;©2017 Baidu &lt;a href=http://www.baidu.com/duty/&gt;使用百度前必读&lt;/a&gt;  &lt;a href=http://jianyi.baidu.com/ class=cp-feedback&gt;意见反馈&lt;/a&gt; 京ICP证030173号  &lt;img src=//www.baidu.com/img/gs.gif&gt; &lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/body&gt; &lt;/html&gt;</span><br><span class="line">+++ exited with 0 +++</span><br></pre></td></tr></table></figure>

<p>  另一个示例，使用 strace 追踪已运行的进程</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# strace -p 903 -e trace=network</span><br><span class="line">strace: Process 903 attached</span><br><span class="line">--- SIGCHLD &#123;si_signo=SIGCHLD, si_code=CLD_EXITED, si_pid=18908, si_uid=0, si_status=255, si_utime=0, si_stime=0&#125; ---</span><br><span class="line">accept(3, &#123;sa_family=AF_INET, sin_port=htons(34004), sin_addr=inet_addr(&quot;192.168.214.254&quot;)&#125;, [128-&gt;16]) = 5</span><br><span class="line">socketpair(AF_UNIX, SOCK_STREAM, 0, [8, 9]) = 0</span><br></pre></td></tr></table></figure>

<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>  实际上可使用的方法不止上文提及的几种手段，也可以通过 ebpf 等方式来实现进程连接信息的捕获。本文仅列出了常见的集中可用手段。</p>
<p>  最后对这几个方法进行简单的小结，见下表</p>
<table>
<thead>
<tr>
<th>方法</th>
<th>示例</th>
<th>特点</th>
</tr>
</thead>
<tbody><tr>
<td>ss 指令</td>
<td>ss -t  -p | grep &lt;进程ID&gt;</td>
<td>需要借助 while 的方法实现实时查看<br>精确度不能完全保证，查询之间存在间隔<br>不能查看历史的连接信息<br>系统默认会有 ss 指令，不需要额外去安装</td>
</tr>
<tr>
<td>audit 日志</td>
<td>tail &#x2F;var&#x2F;log&#x2F;audit&#x2F;audit.log</td>
<td>可查阅历史连接信息<br>依赖环境打开 audit 功能</td>
</tr>
<tr>
<td>perf 工具</td>
<td>perf record -e ‘syscalls:sys_enter_connect’ -p &lt;进程ID&gt;</td>
<td>精确度有保障，可实时捕获数据并写入到一个结果文件，便于事后分析。<br>同样的不支持查看历史的连接信息</td>
</tr>
<tr>
<td>lsof 工具</td>
<td>lsof -i -a -p &lt;进程ID&gt;</td>
<td>基本同 ss 指令</td>
</tr>
<tr>
<td>strace 工具</td>
<td>strace -e trace&#x3D;network -p &lt;进程ID&gt;</td>
<td>精确度有保障，可实时捕获数据<br>支持单条命令调试，也支持加载现有进程。<br>同样的不支持查看历史的连接信息。</td>
</tr>
</tbody></table>
<p> 基于上述的汇总，可以看出这些指令直接是可以取合集做一个工具实现更好的信息捕获的。后续可以实现一个自动化的工具，加入到 orca-tools 里面。</p>
]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>搭建 Kubernetes 私有化镜像仓库 registry</title>
    <url>/2023/08/15/%E6%90%AD%E5%BB%BA%E7%A7%81%E6%9C%89%E5%8C%96%E9%95%9C%E5%83%8F%E4%BB%93%E5%BA%93%20registry/</url>
    <content><![CDATA[<h1 id="1-背景"><a href="#1-背景" class="headerlink" title="1. 背景"></a>1. 背景</h1><p>  在使用 Kubernetes 平台过程中，常常会有搭建私有镜像仓库的需求。而本文主要是记录如何在 Kubernetes 集群上，以 staticpod 的方式快速拉起一个单实例的 registry。以提供容器镜像存储使用。</p>
<h1 id="2-部署步骤"><a href="#2-部署步骤" class="headerlink" title="2. 部署步骤"></a>2. 部署步骤</h1><h2 id="2-1-创建-registry-需要使用的证书"><a href="#2-1-创建-registry-需要使用的证书" class="headerlink" title="2.1. 创建 registry 需要使用的证书"></a>2.1. 创建 registry 需要使用的证书</h2><p>  docker 提供的 registry 默认情况下需要配置 HTTPS 证书，所以我们在搭建前需要先获取 HTTPS 证书。而证书的获取则是通过自签名证书的方式实现。值得注意的是，新版本 go 1.15 以上对证书字段存在要求，必须使用” SAN 字段”。否则在使用过程中，可能会触发下面的错误：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">error: failed to solve: registry.sealos.hub:5000/library/nginx:latest: failed to do request:</span> <span class="string">Head</span> <span class="attr">&quot;https://registry.sealos.hub:5000/v2/library/nginx/manifests/latest&quot;:</span> <span class="attr">tls: failed to verify certificate: x509:</span> <span class="string">certificate</span> <span class="string">relies</span> <span class="string">on</span> <span class="string">legacy</span> <span class="string">Common</span> <span class="string">Name</span> <span class="string">field,</span> <span class="string">use</span> <span class="string">SANs</span> <span class="string">instead</span></span><br></pre></td></tr></table></figure>

<p>以下是自签名证书实现的过程。</p>
<h3 id="2-1-1-创建证书信息文件"><a href="#2-1-1-创建证书信息文件" class="headerlink" title="2.1.1. 创建证书信息文件"></a>2.1.1. 创建证书信息文件</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 创建证书信息文件 openssl.cnf</span><br><span class="line"># 其中 alt_names 的 IP、DNS 字段可以根据实际需要去增加和修改。</span><br><span class="line"></span><br><span class="line">[req]</span><br><span class="line">req_extensions = v3_req</span><br><span class="line">distinguished_name = req_distinguished_name</span><br><span class="line"></span><br><span class="line">[req_distinguished_name]</span><br><span class="line">countryName = Country Name (2 letter code)</span><br><span class="line">countryName_default = XX</span><br><span class="line">stateOrProvinceName = State or Province Name (full name)</span><br><span class="line">stateOrProvinceName_default = YourState</span><br><span class="line">localityName = Locality Name (eg, city)</span><br><span class="line">localityName_default = YourCity</span><br><span class="line">organizationName = Organization Name (eg, company)</span><br><span class="line">organizationName_default = YourCompany</span><br><span class="line">commonName = Common Name (e.g. server FQDN or YOUR name)</span><br><span class="line">commonName_max = 64</span><br><span class="line"></span><br><span class="line">[v3_req]</span><br><span class="line">subjectAltName = @alt_names</span><br><span class="line"></span><br><span class="line">[alt_names]</span><br><span class="line">DNS.1 = sealos.hub</span><br><span class="line">DNS.2 = registry.sealos.hub</span><br><span class="line">IP.1 = 192.168.214.101</span><br><span class="line">IP.2 = 192.168.214.1</span><br></pre></td></tr></table></figure>

<h3 id="2-1-2-创建自签名证书"><a href="#2-1-2-创建自签名证书" class="headerlink" title="2.1.2. 创建自签名证书"></a>2.1.2. 创建自签名证书</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 生成私钥文件</span></span><br><span class="line">openssl genpkey -algorithm RSA -out registry.key</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成证书签名（CSR）文件，一直回车</span></span><br><span class="line">openssl req -new -key registry.key -out registry.csr -config openssl.cnf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用私钥和配置文件生成自签名证书</span></span><br><span class="line">openssl x509 -req -signkey registry.key -<span class="keyword">in</span> registry.csr -out registry.crt -extensions v3_req -extfile openssl.cnf -days 36500</span><br></pre></td></tr></table></figure>

<h2 id="2-2-创建-registry-的-staticPod"><a href="#2-2-创建-registry-的-staticPod" class="headerlink" title="2.2. 创建 registry 的 staticPod"></a>2.2. 创建 registry 的 staticPod</h2><p>  新建 registry.yaml 文件，存放在 &#x2F;etc&#x2F;kubernetes&#x2F;manifests&#x2F; 目录下，内容如下</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">creationTimestamp:</span> <span class="literal">null</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">component:</span> <span class="string">registry</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">registry</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">registry:2</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">private-repository-k8s</span></span><br><span class="line">      <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line">      <span class="attr">env:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">REGISTRY_HTTP_TLS_CERTIFICATE</span></span><br><span class="line">        <span class="attr">value:</span> <span class="string">&quot;/certs/registry.crt&quot;</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">REGISTRY_HTTP_TLS_KEY</span></span><br><span class="line">        <span class="attr">value:</span> <span class="string">&quot;/certs/registry.key&quot;</span></span><br><span class="line">      <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">5000</span></span><br><span class="line">      <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">certs-vol</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/certs</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">registry-vol</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/var/lib/registry</span></span><br><span class="line">  <span class="attr">hostNetwork:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">priorityClassName:</span> <span class="string">system-node-critical</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">certs-vol</span></span><br><span class="line">    <span class="attr">hostPath:</span></span><br><span class="line">      <span class="attr">path:</span> <span class="string">/opt/certs</span></span><br><span class="line">      <span class="attr">type:</span> <span class="string">Directory</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">registry-vol</span></span><br><span class="line">    <span class="attr">hostPath:</span></span><br><span class="line">      <span class="attr">path:</span> <span class="string">/opt/registry</span></span><br><span class="line">      <span class="attr">type:</span> <span class="string">Directory</span></span><br><span class="line"><span class="attr">status:</span> &#123;&#125;</span><br></pre></td></tr></table></figure>

<p>  此处的 volumes 字段，certs-vol、registry-vol 的 path 路径可以根据实际存储位置进行调整。</p>
<p>  执行完成以后，通过 kubectl get pod -n kube-system -o wide | grep registry，就可以看到创建出的 registry pod。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@k8s-master01certs]<span class="comment"># kubectl get pod -n kube-system -o wide | grep registry</span></span><br><span class="line">registry-k8s-master01                      1/1     Running   2          4h36m   192.168.214.101   k8s-master01   &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></table></figure>

<h2 id="2-3-如何解决客户端不信任-registry-提供自签名证书"><a href="#2-3-如何解决客户端不信任-registry-提供自签名证书" class="headerlink" title="2.3. 如何解决客户端不信任 registry 提供自签名证书"></a>2.3. 如何解决客户端不信任 registry 提供自签名证书</h2><p>  经过上述步骤以后，此时可以通过 nerdctl push 测试镜像推送，如果是自签名证书，此时可能会触发如下报错</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">tls: failed to verify certificate: x509: certificate signed by unknown authority</span><br></pre></td></tr></table></figure>

<p>  这是因为客户端没有信任 registry 提供的 HTTPS 证书导致的，对于这种问题，可解决的方法：</p>
<ul>
<li><p>关闭客户端的 HTTPS 校验功能，忽略不受信任。– 对于测试、学习环境，可以通过该方式快速解决。</p>
</li>
<li><p>通过配置客户端，将自签名证书添加到受信任的证书列表。 – 虽然操作起来比较复杂，但这种方式相对安全的多。</p>
<p>需要提醒的是笔者使用的是 containerd 而非 docker，所以操作方式以 containerd 为例。</p>
</li>
</ul>
<h3 id="2-3-1-关闭-HTTPS-校验"><a href="#2-3-1-关闭-HTTPS-校验" class="headerlink" title="2.3.1. 关闭 HTTPS 校验"></a>2.3.1. 关闭 HTTPS 校验</h3><p>  参考如下方法来完成 HTTPS 校验关闭的动作</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 编辑 /etc/containerd/config.toml 追加如下配置</span></span><br><span class="line">    [plugins.<span class="string">&quot;io.containerd.grpc.v1.cri&quot;</span>.registry]</span><br><span class="line">      [plugins.<span class="string">&quot;io.containerd.grpc.v1.cri&quot;</span>.registry.configs.<span class="string">&quot;registry.sealos.hub:5000&quot;</span>.tls]</span><br><span class="line">        insecure_skip_verify = <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 环境可能默认没有 /etc/containerd/config.toml 文件，可以通过 containerd config dump &gt; /etc/containerd/config.toml 去生成</span></span><br></pre></td></tr></table></figure>

<h3 id="2-3-2-为-containerd-添加-HTTPS-证书"><a href="#2-3-2-为-containerd-添加-HTTPS-证书" class="headerlink" title="2.3.2. 为 containerd 添加 HTTPS 证书"></a>2.3.2. 为 containerd 添加 HTTPS 证书</h3><p>   我们可以将 HTTPS 证书放置在 &#x2F;etc&#x2F;containerd&#x2F;certs.d 目录下，需要在所有 node 上执行这个动作。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 如果没有 /etc/containerd/certs.d 目录，则需要创建</span></span><br><span class="line"><span class="built_in">mkdir</span> -p /etc/containerd/certs.d</span><br><span class="line"><span class="comment"># 将 2.1.2. 生成的上传证书文件到 /etc/containerd/certs.d/ 目录下</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果环境配置了 buildkitd，此时也需要追加证书</span></span><br><span class="line">修改 buildkitd 配置文件的内容 /etc/buildkit/buildkitd.toml</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加如下内容，将对应镜像仓库信息、证书路径写入</span></span><br><span class="line">[registry.<span class="string">&quot;registry.sealos.hub:5000&quot;</span>]</span><br><span class="line">  http = <span class="literal">false</span></span><br><span class="line">  insecure = <span class="literal">false</span></span><br><span class="line">  ca=[<span class="string">&quot;/opt/certs/registry.crt&quot;</span>]</span><br><span class="line">  [[registry.<span class="string">&quot;registry.sealos.hub:5000&quot;</span>.keypair]]</span><br><span class="line">    key=<span class="string">&quot;/opt/certs/registry.key&quot;</span></span><br><span class="line">    cert=<span class="string">&quot;/opt/certs/registry.crt&quot;</span></span><br><span class="line">[worker.containerd]</span><br><span class="line">  namespace = <span class="string">&quot;k8s.io&quot;</span></span><br></pre></td></tr></table></figure>

<h2 id="2-4-验证上传下载功能"><a href="#2-4-验证上传下载功能" class="headerlink" title="2.4. 验证上传下载功能"></a>2.4. 验证上传下载功能</h2><p>  经过上述的步骤以后，就可以在客户端侧进行镜像的推拉测试，测试无误后。至此镜像仓库搭建已完成。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 从公网拉取镜像</span></span><br><span class="line"><span class="comment"># 修改 tag</span></span><br><span class="line">nerdctl --namespace k8s.io tag daocloud.io/nginx:latest registry.sealos.hub:5000/library/nginx:latest</span><br><span class="line"><span class="comment"># 推送</span></span><br><span class="line">nerdctl --namespace k8s.io push registry.sealos.hub:5000/library/nginx:latest</span><br><span class="line"><span class="comment"># 拉取镜像</span></span><br><span class="line">nerdctl --namespace k8s.io registry.sealos.hub:5000/library/nginx:latest</span><br></pre></td></tr></table></figure>

<p>参考链接：</p>
<p><a href="https://github.com/moby/buildkit/blob/master/docs/buildkitd.toml.md">https://github.com/moby/buildkit/blob/master/docs/buildkitd.toml.md</a></p>
]]></content>
      <tags>
        <tag>K8S</tag>
      </tags>
  </entry>
  <entry>
    <title>如何查看进程属于哪个容器</title>
    <url>/2023/09/11/%E5%A6%82%E4%BD%95%E6%9F%A5%E7%9C%8B%E8%BF%9B%E7%A8%8B%E5%B1%9E%E4%BA%8E%E5%93%AA%E4%B8%AA%E5%AE%B9%E5%99%A8/</url>
    <content><![CDATA[<h2 id="1-背景"><a href="#1-背景" class="headerlink" title="1. 背景"></a><strong>1.</strong> 背景</h2><p> 项目上可能会遇到一种场景，运维同学反馈某几个进程存在异常（CPU、内存占用率过高），希望定位出这些进程是哪些业务去创建的此时可以根据本文的处理方法进行诊断。</p>
<h2 id="2-处理方法"><a href="#2-处理方法" class="headerlink" title="2. 处理方法"></a>2. 处理方法</h2><h3 id="2-1-方法一：查看各个容器环境中，是否有对应进程名称在运行"><a href="#2-1-方法一：查看各个容器环境中，是否有对应进程名称在运行" class="headerlink" title="2.1. 方法一：查看各个容器环境中，是否有对应进程名称在运行"></a>2.1. 方法一：查看各个容器环境中，是否有对应进程名称在运行</h3><p>执行如下指令获取各个容器中运行的进程</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">for id in $(docker ps -q | xargs); do echo echo &quot;----$id----&quot; ; docker top $id | grep 进程名称 ; done</span><br></pre></td></tr></table></figure>

<p>将获取到有回显的结果，进一步执行 docker ps -a | grep $id 来确认容器名称</p>
<p> </p>
<p>kubernetes 的容器命名规则： <code>k8s_&#123;containerName&#125;_&#123;podFullName&#125;_&#123;namespace&#125;_&#123;podUID&#125;_&#123;podrestartCount&#125;</code></p>
<p>通过 docker ps 获取到的容器名称，根据 podFullName 和 namespace 的命名，我们就能判断这个容器属于哪个命名空间下。</p>
<p> </p>
<h3 id="2-2-方法二：通过进程当前的-cgroup-判断它属于哪个容器或者-Pod"><a href="#2-2-方法二：通过进程当前的-cgroup-判断它属于哪个容器或者-Pod" class="headerlink" title="2.2. 方法二：通过进程当前的 cgroup 判断它属于哪个容器或者 Pod"></a><strong>2.2.</strong> 方法二：通过进程当前的 cgroup 判断它属于哪个容器或者 Pod</h3><p>通过查看 &#x2F;proc&#x2F;PID&#x2F;cgroup 文件，通过其中的pod字段来确认进程是否属于容器环境</p>
<p>cat &#x2F;proc&#x2F;xxxx&#x2F;cgroup</p>
<h2 id="3-示例：获取某个进程的-PID，该-PID-属于运行在容器环境"><a href="#3-示例：获取某个进程的-PID，该-PID-属于运行在容器环境" class="headerlink" title="3. 示例：获取某个进程的 PID，该 PID 属于运行在容器环境"></a>3. 示例：获取某个进程的 PID，该 PID 属于运行在容器环境</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@master1 ~]# cat /proc/7644/cgroup</span><br><span class="line"></span><br><span class="line">11:cpuset:/kubepods/besteffort/podda498366ad0b5d5f487968aaa924c6ab/7f77d3c235e601df71a70530fee4677230a768bd4442d46bad27210f6e520edc</span><br><span class="line"></span><br><span class="line">10:perf_event:/kubepods/besteffort/podda498366ad0b5d5f487968aaa924c6ab/7f77d3c235e601df71a70530fee4677230a768bd4442d46bad27210f6e520edc</span><br><span class="line"></span><br><span class="line">9:memory:/kubepods/besteffort/podda498366ad0b5d5f487968aaa924c6ab/7f77d3c235e601df71a70530fee4677230a768bd4442d46bad27210f6e520edc</span><br><span class="line"></span><br><span class="line">8:hugetlb:/kubepods/besteffort/podda498366ad0b5d5f487968aaa924c6ab/7f77d3c235e601df71a70530fee4677230a768bd4442d46bad27210f6e520edc</span><br><span class="line"></span><br><span class="line">7:devices:/kubepods/besteffort/podda498366ad0b5d5f487968aaa924c6ab/7f77d3c235e601df71a70530fee4677230a768bd4442d46bad27210f6e520edc</span><br><span class="line"></span><br><span class="line">6:pids:/kubepods/besteffort/podda498366ad0b5d5f487968aaa924c6ab/7f77d3c235e601df71a70530fee4677230a768bd4442d46bad27210f6e520edc</span><br><span class="line"></span><br><span class="line">5:freezer:/kubepods/besteffort/podda498366ad0b5d5f487968aaa924c6ab/7f77d3c235e601df71a70530fee4677230a768bd4442d46bad27210f6e520edc</span><br><span class="line"></span><br><span class="line">4:net_prio,net_cls:/kubepods/besteffort/podda498366ad0b5d5f487968aaa924c6ab/7f77d3c235e601df71a70530fee4677230a768bd4442d46bad27210f6e520edc</span><br><span class="line"></span><br><span class="line">3:blkio:/kubepods/besteffort/podda498366ad0b5d5f487968aaa924c6ab/7f77d3c235e601df71a70530fee4677230a768bd4442d46bad27210f6e520edc</span><br><span class="line"></span><br><span class="line">2:cpuacct,cpu:/kubepods/besteffort/podda498366ad0b5d5f487968aaa924c6ab/7f77d3c235e601df71a70530fee4677230a768bd4442d46bad27210f6e520edc</span><br><span class="line"></span><br><span class="line">1:name=systemd:/kubepods/besteffort/podda498366ad0b5d5f487968aaa924c6ab/7f77d3c235e601df71a70530fee4677230a768bd4442d46bad27210f6e520edc</span><br></pre></td></tr></table></figure>

<p>其中 podda498366ad0b5d5f487968aaa924c6ab 就是该进程所属的 pod，此时通过 docker ps -a | grep da4983 可以确认进程所属容器</p>
]]></content>
      <tags>
        <tag>K8S</tag>
      </tags>
  </entry>
  <entry>
    <title>Pod 状态 Evicted 处理思路</title>
    <url>/2022/01/17/Evicted/</url>
    <content><![CDATA[<h1 id="1-现象描述"><a href="#1-现象描述" class="headerlink" title="1. 现象描述"></a><strong>1. 现象描述</strong></h1><p>如果 Pod 处于 Evicted 状态，这意味着当前集群有部分节点存在压力，可能这些节点是内存、磁盘、PID等资源不足，此时需要通过kubectl describe pod名称 -n 命名空间 获取该 Pod 相关的 Events。基于 Events 给出的信息来处理。实例输出如下</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@tke-192-168-0-2 ~]# kubectl describe pod -n cpaas-system warlock-84fdf6cd9b-vkgkz</span><br><span class="line">Name:                 warlock-84fdf6cd9b-vkgkz</span><br><span class="line">Namespace:            cpaas-system</span><br><span class="line">Priority:             1000000</span><br><span class="line">Priority Class Name:  high-priority</span><br><span class="line">Node:                 192.168.0.25</span><br><span class="line">Start Time:           Wed, 03 Nov 2021 09:36:35 +0800</span><br><span class="line">Labels:               app=warlock</span><br><span class="line">                      chart=cpaas-monitor</span><br><span class="line">                      pod-template-hash=84fdf6cd9b</span><br><span class="line">                      service_name=warlock</span><br><span class="line">                      version=v1</span><br><span class="line">Annotations:          ovn.kubernetes.io/allocated: true</span><br><span class="line">                      ovn.kubernetes.io/cidr: 10.199.0.0/16</span><br><span class="line">                      ovn.kubernetes.io/gateway: 10.199.0.1</span><br><span class="line">                      ovn.kubernetes.io/ip_address: 10.199.15.74</span><br><span class="line">                      ovn.kubernetes.io/logical_switch: ovn-default</span><br><span class="line">                      ovn.kubernetes.io/mac_address: 00:00:00:CD:F8:38</span><br><span class="line">                      ovn.kubernetes.io/network_types: geneve</span><br><span class="line">                      ovn.kubernetes.io/routed: true</span><br><span class="line">Status:               Failed</span><br><span class="line">Reason:               Evicted</span><br><span class="line">Message:              Pod The node had condition: [DiskPressure]. # 对于 Evicted 的 Pod，重点关注 Message 字段的内容，通过该字段判断原因。从示例来看，问题出节点触发了 DiskPressure。</span><br><span class="line">IP:</span><br><span class="line">IPs:                  </span><br><span class="line">Controlled By:        ReplicaSet/warlock-84fdf6cd9b</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<h1 id="2-排查思路"><a href="#2-排查思路" class="headerlink" title="2. 排查思路"></a><strong>2. 排查思路</strong></h1><h2 id="2-1-节点资源类"><a href="#2-1-节点资源类" class="headerlink" title="2.1. 节点资源类"></a><strong>2.1. 节点资源类</strong></h2><h3 id="2-1-1-磁盘空间不足"><a href="#2-1-1-磁盘空间不足" class="headerlink" title="2.1.1. 磁盘空间不足"></a><strong>2.1.1. 磁盘空间不足</strong></h3><h4 id="2-1-1-1-故障现象"><a href="#2-1-1-1-故障现象" class="headerlink" title="2.1.1.1. 故障现象"></a><strong>2.1.1.1. 故障现象</strong></h4><p>通过 kubectl describe pod 获取到的错误信息如下，关键字段在 Message 处，关键字段 The node was low on resource</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 示例输出</span></span><br><span class="line">[root@k8s-1 ~]<span class="comment"># kubectl describe pod nginx-6db6848cf4-gr46n</span></span><br><span class="line">....</span><br><span class="line">Status:         Failed</span><br><span class="line">Reason:         Evicted</span><br><span class="line">Message:        The node was low on resource: ephemeral-storage. Container nginx was using 5594, <span class="built_in">which</span> exceeds its request of 0.</span><br><span class="line">...</span><br><span class="line">Events:</span><br><span class="line">  Type     Reason            Age    From               Message</span><br><span class="line">  ----     ------            ----   ----               -------</span><br><span class="line">  Normal   Scheduled         2m40s  default-scheduler  Successfully assigned default/nginx-6db6848cf4-gr46n to k8s-2</span><br><span class="line">  Normal   Pulling           2m38s  kubelet            Pulling image <span class="string">&quot;daocloud.io/nginx&quot;</span></span><br><span class="line">  Normal   Pulled            2m38s  kubelet            Successfully pulled image <span class="string">&quot;daocloud.io/nginx&quot;</span> <span class="keyword">in</span> 572.503087ms</span><br><span class="line">  Normal   Created           2m38s  kubelet            Created container nginx</span><br><span class="line">  Normal   Started           2m38s  kubelet            Started container nginx</span><br><span class="line">  Warning  Evicted           60s    kubelet            The node was low on resource: ephemeral-storage. Container nginx was using 5594, <span class="built_in">which</span> exceeds its request of 0.</span><br><span class="line">  Normal   Killing           60s    kubelet            Stopping container nginx</span><br></pre></td></tr></table></figure>

<h4 id="2-1-1-2-处理思路"><a href="#2-1-1-2-处理思路" class="headerlink" title="2.1.1.2. 处理思路"></a><strong>2.1.1.2. 处理思路</strong></h4><p>从 low on resource 反馈的资源类型来判断是内存不足、磁盘空间不足还是 PID 不足。从现网处理的案例来看，基本上都是磁盘不足引起的问题。对于磁盘空间不足的场景，需要登录到异常节点上，通过 dh 查询各个目录的使用空间，定位到占用容量的文件，并通过释放或者扩容的手段处理。</p>
<p>磁盘压力分为 <strong>根文件系统</strong> 和 <strong>映像文件系统</strong> 这两种，映像文件系统指的是 docker 或者其他 CRI 的数据盘。对于 TKE 来说通常会单独给 &#x2F;var&#x2F;lib&#x2F;docker 单独挂盘，TCNP 会给 &#x2F;data 单独挂盘。</p>
<p>默认情况下，<strong>根分区文件系统的使用容量达到 90%</strong> 或者 inodes 达到 95% 就会触发驱逐，并自动打上污点。<strong>映像文件系统则是使用容量达到 85%</strong> 就会触发驱逐并自动打上污点。</p>
<p>从现网的处理经验来看，造成磁盘容量使用率高的原因，通常原因如下：</p>
<ul>
<li><p>产品出包的配置误将日志输出到根分区，常出现在 TI 产品，当我们追查到空间使用率来源于组件日志时，需要拉起后端同学确认，擦看是否可以先清理掉过期的日志，再整改日志存放路径。</p>
</li>
<li><p>相关同学在初始化节点时操作不正确，未正确挂载数据盘。导致后续数据全部写入到了根分区，造成根分区磁盘压力大。</p>
</li>
<li><p>相关同学在初期部署时将所有物料到根分区，造成磁盘空间不足。</p>
</li>
<li><p>初期交付时磁盘空间规划较小。该类场景比较容易导致磁盘爆满。</p>
</li>
</ul>
<h4 id="2-1-1-3-处理步骤"><a href="#2-1-1-3-处理步骤" class="headerlink" title="2.1.1.3. 处理步骤"></a><strong>2.1.1.3. 处理步骤</strong></h4><p><strong>1、登录到故障节点</strong></p>
<p><code>通过 ssh 用户名@IP 进行连接，细节略</code></p>
<p><strong>2、查询磁盘使用率</strong></p>
<p><code>通过 df | grep -v -E &quot;overlay|shm|tmpfs&quot; 可以获取节点当前磁盘使用的情况。</code></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 示例输出，这个环境不存在 DiskPressure</span></span><br><span class="line">[root@tke-192-168-0-2 ~]<span class="comment"># df | grep -v -E &quot;overlay|shm|tmpfs&quot;</span></span><br><span class="line">Filesystem                 1K-blocks      Used Available Use% Mounted on</span><br><span class="line">/dev/vda1                  154685884  83911048  64383392  57% /          <span class="comment"># 如果根分区超过 90% 就会触发驱逐</span></span><br><span class="line">/dev/mapper/vgdata-lv_data 524027908 409582764 114445144  79% /data/platform</span><br><span class="line">ceph-fuse                  775245824 416186368 359059456  54% /data/platform-fs</span><br><span class="line">通过 <span class="built_in">df</span> -i | grep -v -E <span class="string">&quot;overlay|shm|tmpfs&quot;</span> 可以获取节点当前磁盘 inodes 使用的情况。</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例输出，注：这个环境不存在 DiskPressure</span></span><br><span class="line">[root@tke-192-168-0-2 ~]<span class="comment"># df -i | grep -v -E &quot;overlay|shm|tmpfs&quot;</span></span><br><span class="line">Filesystem                    Inodes   IUsed     IFree IUse% Mounted on</span><br><span class="line">/dev/vda1                    9830400  313679   9516721    4% /</span><br><span class="line">/dev/mapper/vgdata-lv_data 231136976 2412258 228724718    2% /data/platform</span><br><span class="line">ceph-fuse                      33487   33487         0  100% /data/platform-fs</span><br></pre></td></tr></table></figure>

<p><strong>3、定位占用磁盘空间的文件</strong></p>
<p><strong>a. 确认各个目录的空间占用率</strong></p>
<p>通过 du -h –max-depth&#x3D;1 &#x2F; 可以获取节点当前磁盘使用的情况。通过这个方法我们可以追查磁盘使用率是来源于哪些目录。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 示例输出</span></span><br><span class="line">[root@k8s ~]<span class="comment"># du -h --max-depth=1 /</span></span><br><span class="line">118M    /boot</span><br><span class="line">0       /dev</span><br><span class="line"><span class="built_in">du</span>: cannot access ‘/proc/5891’: No such file or directory</span><br><span class="line"><span class="built_in">du</span>: cannot access ‘/proc/5944/task/5944/fd/3’: No such file or directory</span><br><span class="line"><span class="built_in">du</span>: cannot access ‘/proc/5944/task/5944/fdinfo/3’: No such file or directory</span><br><span class="line"><span class="built_in">du</span>: cannot access ‘/proc/5944/fd/4’: No such file or directory</span><br><span class="line"><span class="built_in">du</span>: cannot access ‘/proc/5944/fdinfo/4’: No such file or directory</span><br><span class="line">0       /proc</span><br><span class="line">794M    /run</span><br><span class="line">0       /sys</span><br><span class="line">36M     /etc</span><br><span class="line">29G     /root  <span class="comment"># 空间使用率较高，从此处可以看到，根分区的空间基本上是被 /root 使用掉了。</span></span><br><span class="line">754M    /var</span><br><span class="line">4.0K    /tmp</span><br><span class="line">1.5G    /usr</span><br><span class="line">0       /home</span><br><span class="line">0       /media</span><br><span class="line">0       /mnt</span><br><span class="line">88M     /opt</span><br><span class="line">0       /srv</span><br><span class="line">33G     /</span><br></pre></td></tr></table></figure>

<p>通过 du 追查到一级目录以后，再一步一步的追查，示例中是 &#x2F;root 使用空间较大，后续再通过 du -h –max-depth&#x3D;1 &#x2F;root 进一步的获取空间使用情况。循序渐进找到源头。</p>
<p><strong>b. 确认是否存在未释放 Evicted Pod</strong></p>
<p>在确认节点资源问题已解决后，各个业务 Pod 应该重新调度。此时需要将这些 Evicted 的 Pod 释放掉。执行如下指令完成</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 生产不要直接复制~~~~</span></span><br><span class="line"><span class="keyword">for</span> ns <span class="keyword">in</span> `kubectl get ns |awk <span class="string">&#x27;NR&gt;1&#123;print $1&#125;&#x27;</span>` ;<span class="keyword">do</span> kubectl get pod -n &#123;ns&#125; |grep Evicted |awk <span class="string">&#x27;&#123;print 1&#125;&#x27;</span>|xargs kubectl delete pod -n <span class="variable">$&#123;ns&#125;</span> ;<span class="keyword">done</span></span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>K8S</tag>
      </tags>
  </entry>
  <entry>
    <title>边缘计算杂记一：概念</title>
    <url>/2024/01/31/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E6%9D%82%E8%AE%B0%E4%B8%80%EF%BC%9A%E6%A6%82%E5%BF%B5/</url>
    <content><![CDATA[<p><strong>什么是边缘计算？它具备什么价值？</strong></p>
<p>  边缘计算（Edge Computing）是一种分布式计算的架构，将计算和数据处理的能力推向离数据源和用户更近的边缘设备上。边缘设备可以是工控机、路由器、网关、传感器等，这些设备都有一定的计算、存储和网络连接能力。</p>
<p>  边缘计算的价值在于：</p>
<ul>
<li><p>减少数据传输延迟：边缘设备位于数据源和用户之间，可以避免长距离的数据传输，减少了数据传输延迟。</p>
</li>
<li><p>提供实时决策和响应：由于边缘设备的计算和数据处理能力强大，可以实时对数据进行处理和分析，对数据进行过滤、聚合、计算等，快速做出决策和响应。</p>
</li>
<li><p>提高网络安全性：由于数据处理在边缘设备上进行，有助于减少对云端和网络的依赖性，从而提高系统的安全性和可靠性。</p>
</li>
<li><p>降低云计算成本：通过使用边缘计算，可以将计算和数据处理从云端下移，减少云计算的负载和成本。</p>
</li>
<li><p>支持物联网应用：边缘计算的应用场景非常适合物联网领域，因为物联网涉及到大量的传感器和设备，需要对这些设备产生的数据进行实时监控和分析，并做出实时决策和调整。</p>
<p>边缘计算的典型应用包括自动驾驶、智能家居、智能制造、智慧城市等领域，在这些应用场景中，边缘计算可以快速响应用户需求，处理实时数据并进行决策。这种分布式计算架构的优势在于提高了系统的性能和效率，并能够更好地满足复杂的实时业务需求。</p>
</li>
</ul>
<p><strong>边缘计算的架构大概是怎么样的？</strong></p>
<p>  边缘计算的架构通常包括以下几个主要组件：</p>
<ol>
<li><p>边缘设备（Edge Devices）：边缘设备是指部署在离数据源和用户更近的位置上的设备，例如传感器、工控机、路由器、智能手机等。这些设备具备一定的计算、存储和网络连接能力，能够处理和分析数据，并执行一些简单的计算任务。</p>
</li>
<li><p>边缘节点（Edge Nodes）：边缘节点是一组连接在一起的边缘设备，它们协同工作，共同处理和管理数据。边缘节点可以是一个集群、网关或者边缘服务器等。边缘节点负责接收、存储、处理和转发来自边缘设备的数据，并与云端或中心节点进行通信。</p>
</li>
<li><p>云端或中心节点（Cloud or Central Nodes）：云端或中心节点是位于数据中心或云平台的中央服务器，负责接收、存储和管理从边缘节点传输过来的数据。云端或中心节点具备强大的计算和存储能力，可以执行复杂的数据分析和处理任务。</p>
</li>
<li><p>网络连接（Network Connectivity）：边缘计算依赖于可靠的网络连接，用于连接边缘设备、边缘节点和云端或中心节点之间的数据传输。可以利用有线网络（如以太网）或者无线网络（如Wi-Fi、蜂窝网络等）来实现连接。</p>
</li>
<li><p>边缘计算软件平台（Edge Computing Software Platform）：边缘计算软件平台提供了管理和协调边缘设备、边缘节点和云端节点之间通信和数据处理的功能。它包括边缘节点操作系统、容器化技术、边缘计算框架等组件，帮助实现数据的分发、处理、存储和安全管理。</p>
</li>
</ol>
<p>在边缘计算架构中，边缘设备收集和生成数据，通过边缘节点进行本地处理和决策，然后将关键数据传输到云端或中心节点进行进一步的分析和计算。这种分布式计算架构能够提高系统的性能和效率，减少数据传输延迟，并支持实时的决策和响应。</p>
<p><strong>边缘计算和 Kubernetes 存在什么关联？</strong></p>
<ol>
<li><p>边缘计算是一种分布式计算模型，它将计算、存储和网络功能推近到数据产生源头和最终用户之间，以提供更低延迟、更高带宽和更好的用户体验。边缘计算可以将计算资源放置在离用户或设备更近的位置，例如工厂、物流中心、智能城市等地方。</p>
</li>
<li><p>Kubernetes（简称K8s）是一个用于自动化容器化应用程序部署、扩展和管理的开源平台。它提供了管理容器化应用程序所需的资源调度、服务发现、负载均衡、弹性伸缩等功能。Kubernetes通过使用容器技术，如Docker，可以简化应用程序的部署和管理，并提供高可用性和弹性的运行环境。</p>
</li>
<li><p>边缘计算和Kubernetes结合在一起，可以实现在边缘设备上部署和管理容器化应用程序的能力。通过在边缘节点上运行Kubernetes集群，可以将容器化的应用程序部署到边缘设备中，实现边缘计算的灵活性和可扩展性。</p>
</li>
<li><p>在边缘计算环境中，通过Kubernetes可以实现容器化应用程序的自动部署、资源调度和服务发现。Kubernetes可以根据边缘设备的资源状况进行自动伸缩，确保应用程序在边缘节点上的高可用性和性能。</p>
</li>
</ol>
<p><strong>边缘计算和 CDN 的关系？</strong></p>
<p>  个人理解边缘计算和 CDN 都属于解决方案，它们之间非常相似。下面是我找到的一个 CDN 与边缘计算联合使用的案例：</p>
<p>  假设有一家电子商务公司，他们的在线平台需要快速响应用户的请求并提供高质量的服务。用户遍布全球各地，访问平台的内容包括网页、图片、视频等。这家电子商务公司决定采用CDN来优化内容传输和加速用户访问体验。他们与CDN服务提供商合作，在全球范围内建立了许多节点服务器，这些节点服务器位于离用户最近的位置。</p>
<p>  当用户请求访问该电子商务平台时，CDN会根据用户的位置选择距离最近的节点服务器来提供所需内容。CDN节点服务器具有缓存功能，如果所请求的内容已经存在于某个节点服务器上，CDN可以直接从该节点服务器中返回内容，而无需通过远程的主要服务器。这样可以大大减少数据传输的延迟，加快内容的加载速度。</p>
<p>  此外，这些CDN节点服务器也可以提供边缘计算的能力。例如，当用户请求访问一个动态生成的页面时，CDN节点服务器可以在接收到请求后执行一些简单的计算任务，如数据处理、模板渲染等，以生成所需的页面，并将结果返回给用户。这样，不仅减少了从主要服务器到用户的数据传输量，还可以提供更快速的响应时间。</p>
<p>  CDN作为边缘计算节点发挥了双重作用。它们不仅通过缓存和分发内容来加速内容传输，提高用户访问体验，而且通过执行一些简单的边缘计算任务，减少了数据传输延迟，并提供更快速的响应。</p>
<p>边缘计算平台，大概需要解决哪些问题？</p>
<p>  如果应用需要在边缘计算的场景下使用，对提供边缘计算能力的平台需要解决下面这几个问题：</p>
<ul>
<li><p>云边通信，边端通常没有固定IP，云端怎么去管控它们？云端又怎么去访问边端上的服务？</p>
</li>
<li><p>边缘自治，边端和云端连通性出现异常时，边端怎么保障还能正常的对外提供服务？</p>
</li>
<li><p>边缘部署，边缘节点间可能存在差异（如ARM、x86 或者服务配置有一些不同），怎么快速把应用发布在边缘节点。</p>
</li>
</ul>
<p>那这里可以通过什么技术或者手段去实现这些能力？</p>
<p><strong>云边通信</strong></p>
<p>  云边通信需要解决的问题是边端没有固定IP，这使得传统的 ssh 主动去连接边缘的机器是无法做到的。边端虽然没办法被云端主动去连接，但可以反过来，让边端主动去连接云端，这时候就可以实现云边通信了。</p>
<p>  所以这里可以设计一个程序，实现这个反向隧道。来解决掉云端和边端之间的通信问题。如 superedge 就是通过 tunnel-cloud、tunnel-edge 组件来实现的反向隧道。让云端可以实现边端管理。</p>
<p><strong>边缘自治</strong></p>
<p>  边缘自治边缘自治，笔者的理解是边缘节点能够自主的去进行决策和协作。实际上这里的实现需要和边缘上的应用实现相关联。我这里只讨论边缘计算的平台（基于 Kubernetes）要怎么实现基础的边缘自治能力。</p>
<p>  如果只考虑到 Kubernetes 这一层次，假设云端和边端节点之间的网络不稳定，出现了几分钟断连的情况，这时候基于 Kubernetes 自身的机制，节点需要每隔一段时间进行上报的动作。当上报失败次数到某个次数，Kubernetes 会认为节点不健康，将状态设置为 NotReady，并驱逐节点上的所有服务。在其他节点上拉起新的工作副本。</p>
<p>  对于边缘计算的场景下，这个设计其实是不可靠的，毕竟边端节点可能没有异常，它只是和云端存在网络通信问题。边端节点自身还是能够给边缘设备提供访问能力的。所以这时候边端节点不能只依赖 Kubernetes 原生的健康检查机制。还需要依赖一些分布式的检查方式。比如某个站点下的边缘节点异常了。那该站点下的其他节点可以和它进行连通性测试。确保该节点只是和云端通信存在异常。本身能力还是可以继续对外提供的。不进行驱逐。</p>
<p>  另外当云端无法访问了，边端节点如果依赖云端的一些个性化数据无法获取到，也可能会造成业务影响，所以边端节点自身也需要去实现一层类似缓存、同步的机制。比如在本地拉起一个简易的数据库程序。将平常访问到云端的一些数据、在脱离云端通信过程中执行的一些决策数据等缓存到本地数据库中。等恢复后再执行同步。</p>
<p><strong>边缘部署</strong></p>
<p>  基于实际环境应用去考虑，边缘部署可能要解决这几个点：</p>
<ul>
<li><p>环境可能存在站点的概念，比如环境下存在非常多的节点。某些边缘节点属于一个站点，某些节点属于另一个站点，我一个边缘应用在同时发布在若干个站点。怎么快速去部署？</p>
</li>
<li><p>部署过程中可能存在差异化的配置，比如边缘节点的 CPU 架构可能是不一致的，比如同时存在 x86 和 arm 架构，那这个时候部署的时候怎么去快速渲染差异化的配置。</p>
<p>那这里就是说要解决站点间部署的差异性，以及快速将应用部署在若干站点。这里就需要 Kubernetes 这一层再去设计一些额外的 CR 资源来实现，以 superedge 为例子。它设计了 NodeUnit、NodeGroup、ServiceGroup 的概念。</p>
<p>我们可以将具备相同属性（例子中就是同一站点）的节点配置划分到 NodeUnit。这样不同站点间它们就归属在不同的 NodeUnit，所有的 NodeUnit 都归属于一个 NodeGroup。然后基于 NodeGroup 可以创建对应的 deploymentGrid。在 deploymentGrid 中可以配置 poolTemplate，将每个不同 NodeUnit 的差异化配置进行设置。实现差异化部署。之后再基于 NodeGroup 可以创建 ServiceGroup。去自动给这些 NodeUnit 部署的应用创建 service。来实现对外服务。</p>
</li>
</ul>
]]></content>
      <tags>
        <tag>K8S</tag>
        <tag>边缘计算</tag>
      </tags>
  </entry>
</search>
